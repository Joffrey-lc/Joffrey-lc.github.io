<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Novel Robust Band-Limited Signal Detection Approach Using Graph梳理</title>
    <link href="/2021/12/04/signalDetectionwithGraph/"/>
    <url>/2021/12/04/signalDetectionwithGraph/</url>
    
    <content type="html"><![CDATA[<h1 id="Novel-Robust-Band-Limited-Signal-Detection-Approach-Using-Graph"><a href="#Novel-Robust-Band-Limited-Signal-Detection-Approach-Using-Graph" class="headerlink" title="Novel Robust Band-Limited Signal Detection Approach Using Graph"></a>Novel Robust Band-Limited Signal Detection Approach Using Graph</h1><p>@<a href="目录">TOC</a></p><h2 id="Paper-Download"><a href="#Paper-Download" class="headerlink" title="Paper Download"></a>Paper Download</h2><p><a href="https://pan.baidu.com/s/1DdZbw4zlOgHQR4fcHH76Dg">原文百度云及提取码</a>：9tok</p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p><strong>Abstract</strong>— In this letter, a novel graph-based adequate and concise information representation paradigm is explored. This new signal representation framework can provide a promising alternative for manifesting the essential structure of the communication signals. A typical application, namely, band-limited signal detection, can thus be carried out using our proposed new graph-based signal characterization. According to Monte Carlo simulation results, the proposed graph-based signal detection method leads to the outstanding performance, compared with other existing techniques especially when the signal-to-noise ratio is rather small.<br><strong>Index Terms</strong>— Graph representation, cyclic spectral analysis,sparse signal, weak signal detection.</p><h1 id="Implemention"><a href="#Implemention" class="headerlink" title="Implemention"></a>Implemention</h1><p>==BY MYSELF==</p><h2 id="一、信号的生成"><a href="#一、信号的生成" class="headerlink" title="一、信号的生成"></a>一、信号的生成</h2><p>根据文中叙述，使用BPSK进行作为实验数据，信噪比分别是-3dB、-7dB、-11dB、-$\infty$dB：<br>Matlab自带有<code>pskmod</code>函数:<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">function y &#x3D; pskmod(x,M,varargin)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">%PSKMOD Phase shift keying modulation%%   Y &#x3D; PSKMOD(X,M) outputs the complex envelope of the modulation of the%   message signal X, using the phase shift keying modulation. M is the%   alphabet size and must be an integer power or 2. The message signal X%   must consist of integers between 0 and M-1. For two-dimensional%   signals, the function treats each column as 1 channel.%%   Y &#x3D; PSKMOD(X,M,INI_PHASE) specifies the desired initial phase in%   INI_PHASE. The default value of INI_PHASE is 0.%%   Y &#x3D; PSKMOD(X,M,INI_PHASE,SYMBOL_ORDER) specifies how the function %   assigns binary words to corresponding integers. If SYMBOL_ORDER is set %   to &#39;bin&#39; (default), then the function uses a natural binary-coded ordering. %   If SYMBOL_ORDER is set to &#39;gray&#39;, then the function uses a Gray-coded%   ordering.%%   See also PSKDEMOD, MODNORM, comm.PSKModulator.%    Copyright 1996-2013 The MathWorks, Inc.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><br>我们可以直接调用基带调制：<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">MPSK&#x3D;2；msg&#x3D;randi([0 MPSK-1],1,nsymbol); %生成基带数据       msgmod&#x3D;pskmod(msg,MPSK).&#39;; %基带B-PSK调制<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div><br>然后再通过载波进行搬移：<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">T0&#x3D;1;%符号周期fs&#x3D;50&#x2F;T0;%采样率t&#x3D;0:1&#x2F;fs:T0-1&#x2F;fs;%时间向量fc&#x3D;2&#x2F;T0; %载波频率 c&#x3D;sqrt(2)*exp(1i*2*pi*fc*t);%载波信号tx&#x3D;real(msgmod*c);%载波调制<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><br>然后对所得信号进行展开，方便后续计算：<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">tx1&#x3D;reshape(tx.&#39;,1,length(msgmod)*length(c));   %tx&#39;的每一列是一个码元代表的采样点,现展开为一行    <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>现在所得信号是没有噪声的。我们通过SNR和信号功率计算噪声功率，并将信号和其对应的噪声相加，完成信号的模拟：<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">for indx&#x3D;1:length(snr_dB)    rx&#x3D;noisegen(tx1,snr_dB(indx),T0,fs); %加入高斯白噪声后的信号    rxy&#x3D;abs(fft(rx,300));%fft    figure(1)%显示fft图像    subplot(4,1,indx)    plot(rxy);    title([&#39;SNR&#x3D;&#39;,num2str(snr_dB(indx)),&#39;dB&#39;]);    xlabel(&#39;fft点数&#39;,&#39;position&#39;,[320 -20]);    ylabel(&#39;幅度&#39;);end<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><br>其中<code>noisegen</code>函数是根据此<a href="https://pdfs.semanticscholar.org/001c/e832fcee885f19c53aa4d3a5b1740df6325f.pdf?_ga=2.266098567.963320733.1592485803-1007630928.1588666286">PAPER</a>自定义的噪声计算及添加。<br>到此完成信号生成（变换到频域）如下：<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200805205741630.jpg" alt="四种信噪比下BPSK频域波形"><center><b><font size ='2'>图1. 四种SNR下的BPSK信号FFT</font></b></center>&lt;/font&gt;</p><h2 id="二、计算功率谱-X-m-并归一化"><a href="#二、计算功率谱-X-m-并归一化" class="headerlink" title="二、计算功率谱$X(m)$,并归一化"></a>二、计算功率谱$X(m)$,并归一化</h2><p>归一化公式：</p><script type="math/tex; mode=display">U_X(m)= \frac{X(m)-\theta_{min}}{\theta_{man}-\theta_{man}} , m=0,1,...M-1</script><p>其中$X(m)$是功率谱，$\theta<em>{max}$和$\theta</em>{min}$是功率谱的最大值和最小值。<br>使用FFT计算得到功率谱$X(m)$：</p><script type="math/tex; mode=display">X(m)\overset{def}{=}\frac{1}{K}|\sum_{k=0}^{K-1}x(k)e^{-j2\pi m\frac{k}{K}}|^2,0\leq m\le M-1</script><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">rxy&#x3D;abs(fft(rx,300));%fftUx&#x3D;zeros(1,length(rxy));%%%%%%%%%%Normalized%%%%%%%%%theta_min&#x3D;min(rxy);theta_max&#x3D;max(rxy);for m&#x3D;1:1:length(rxy)Ux(m)&#x3D;(rxy(m)- sita_min)&#x2F;(sita_max-sita_min);  end<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h2 id="三、量化"><a href="#三、量化" class="headerlink" title="三、量化"></a>三、量化</h2><p>根据论文量化规则：</p><script type="math/tex; mode=display">Q_X(m)\overset{def}{=}\triangle_\gamma(U_X(m)),m=0,1,...,M-1</script><p>得到量化结果：<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">%%%%%%%%%%%%quantization%%%%%%%%%%%for mm&#x3D;1:1:length(Ux)[~,r_level(mm)]&#x3D;min(abs(Ux(mm)-r_set));%找到量化等级end<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><br>以此步骤画图得到Fig.1</p><h2 id="四、构建邻接矩阵、度矩阵和拉普拉斯矩阵"><a href="#四、构建邻接矩阵、度矩阵和拉普拉斯矩阵" class="headerlink" title="四、构建邻接矩阵、度矩阵和拉普拉斯矩阵"></a>四、构建邻接矩阵、度矩阵和拉普拉斯矩阵</h2><p>根据论文可总结为：</p><script type="math/tex; mode=display">\widetilde{A}(Q_X(m),Q_X(m+1))=1,m=1,2,...,M-1</script><p>再通过线性代数定理得到Laplacian Matrix：</p><script type="math/tex; mode=display">L=D-A</script><p>其中$L$是Laplacian，$D$ 是Degree Matrix，$A$是 Adjacency Matrix</p><p>这里用一个自己定义的函数<code>get_LaplacianMatrix</code>来实现：<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">function Lx&#x3D;get_LaplacianMatrix(r,Qx)Ax_bar&#x3D;zeros(r,r);Dx_bar&#x3D;zeros(r,r);for i &#x3D;1:1:length(Qx)-1    if(Qx(i)~&#x3D;Qx(i+1))        Ax_bar(Qx(i),Qx(i+1))&#x3D;1; %半正定矩阵        Ax_bar(Qx(i+1),Qx(i))&#x3D;1;     endendfor j&#x3D;1:1:r   Dx_bar(j,j)&#x3D;sum(Ax_bar(j,:)); endLx&#x3D;Dx_bar-Ax_bar;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></p><h2 id="五、计算Laplacian-Matrix-的第二大特征值及其均值"><a href="#五、计算Laplacian-Matrix-的第二大特征值及其均值" class="headerlink" title="五、计算Laplacian Matrix 的第二大特征值及其均值"></a>五、计算Laplacian Matrix 的第二大特征值及其均值</h2><p>求拉普拉斯矩阵Lx的特征值，记第二大特征值为$\lambda_1$。完成1000次计算，得到均值：</p><script type="math/tex; mode=display">\bar{\lambda}_1= \frac{1}{\psi}\sum_{\nu=1}^{\psi}\lambda_1(\nu)</script><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">Lx&#x3D;get_LaplacianMatrix(r,r_level);%得到laplacian 矩阵[~,lamda]&#x3D;eig(Lx);%计算特征值[not_sort,~]&#x3D;max(lamda);%提取特征值lamda_sort&#x3D;sort(not_sort);%特征值排序lamda0(indx2)&#x3D;lamda_sort(end-1);%找到第二大特征值<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h2 id="六、判断"><a href="#六、判断" class="headerlink" title="六、判断"></a>六、判断</h2><p>==根据文中理论，全联通图的$\bar{\lambda}_1$应该等于量化等级$\gamma$:</p><p><script type="math/tex">{\lim_{x \to \infty}}\lambda_1=\gamma</script>即信噪比很小或全是白噪声时，$|\lambda_1-\gamma|&lt;\delta$。$\delta$是一个很小门限参数。==</p><p>此处定理有待证明。。。</p><h1 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h1><p>此篇文章出了一个大BUG，通过SNR计算噪声功率出现了错误。<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200805221903690.png" alt="正确信噪比下的信号FFT"></p><p><center><b><font size ='2'>图2. 正确信噪比下的信号FFT</font></b></center>&lt;/font&gt;</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200805221950259.png" alt="文章中的信噪比下的信号FFT"></p><p><center><b><font size ='2'>图3. 文章中的信噪比下的信号FFT</font></b></center>&lt;/font&gt;</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/2020080522245893.png" alt="在这里插入图片描述"></p><p><center><b><font size ='2'>图4. 正确信噪比下逼近结果</font></b></center>&lt;/font&gt;</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200805222527152.png" alt="在这里插入图片描述"></p><p><center><b><font size ='2'>图5. 文章中信噪比下的逼近结果</font></b></center>&lt;/font&gt;</p><p>可见，文章中的信噪比添加方式是错误的，没有考虑白噪声的功率谱。<br>完整代码见<a href="https://github.com/Joffrey-lc/Novel-Robust-Band-Limited-Signal-Detection-Approach-Using-Graph">My Github</a>  ==Give me a star plz!==</p>]]></content>
    
    
    <categories>
      
      <category>Paper Reading</category>
      
      <category>Others</category>
      
    </categories>
    
    
    <tags>
      
      <tag>gcn</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GCN小结</title>
    <link href="/2021/12/04/gcn/"/>
    <url>/2021/12/04/gcn/</url>
    
    <content type="html"><![CDATA[<h1 id="入门必看"><a href="#入门必看" class="headerlink" title="入门必看"></a>入门必看</h1><p>推荐顺序由简到难：</p><ol><li><p><a href="https://zhuanlan.zhihu.com/p/71200936">何时能懂你的心——图卷积神经网络（GCN）</a></p></li><li><p><a href="https://www.zhihu.com/question/54504471">知乎Johnny Richards和superbrother的回答</a></p></li><li><p><a href="https://blog.csdn.net/yyl424525/article/details/100058264">CSDN文章</a></p></li><li><p>清华大学综述文章：Graph Neural Networks：A Review of Methods and Applications</p></li><li><p>GCN开山之作：Semi-Supervised Classification With Graph Convolutional Networks</p></li></ol><h1 id="提出思想及发展"><a href="#提出思想及发展" class="headerlink" title="提出思想及发展"></a>提出思想及发展</h1><h2 id="提出"><a href="#提出" class="headerlink" title="提出"></a>提出</h2><p>对于图（pictures）的处理，CNN是一件大法宝；但是由于CNN处理的对象都是Euclidean Structure，无法对Non Euclidean Structure数据进行处理。图（graph）就是典型的Non Euclidean Structure数据。所以GCN（Graph Convolutional Network）应运而生。</p><p>研究GCN的原因，主要可以简答概括为三点（参考知乎<a href="https://www.zhihu.com/question/54504471">superbrother</a> 的回答）：</p><ol><li>CNN无法处理Non Euclidean Structure数据（传统的离散卷积在Non Euclidean Structure数据上无法保持平移不变性）</li><li>希望在拓扑图结构上有效地提取空间特征来进行机器学习</li><li>拓扑连接是一种广义的数据结构，可应用范围广</li></ol><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>因为在Non Euclidean Structure数据中，传统的图像卷积操作（图像上的数据点的加权求和）不能适用，所以要想完成GCN，就需要重新定义卷积操作。<br>现在的卷积思路有两种：</p><h3 id="谱域图卷积"><a href="#谱域图卷积" class="headerlink" title="谱域图卷积"></a>谱域图卷积</h3><ul><li>根据图谱理论和卷积定理，将数据从空（间）域转换到谱域进行处理</li><li>有较强的理论基础</li></ul><p>因为傅里叶变换的一个重要性质：<br><em>函数$f_1(t)$和函数$f_2(t)$的傅里叶变换，等于二者傅里叶变换的乘积的逆变换</em>,即：</p><script type="math/tex; mode=display">f_1(x)*f_2(x)=\mathcal{F^{-1}[\mathcal{F_1(w)}\mathcal{F_2(w)}]}</script><div class="table-container"><table><thead><tr><th>符号</th><th>定义</th></tr></thead><tbody><tr><td>$f_1(x)$、$f_2(x)$</td><td>函数</td></tr><tr><td>$\mathcal{F_1(w)}$、$\mathcal{F_2(w)}$</td><td>对应函数的傅里叶变换</td></tr><tr><td>也就是说只要定义了图（graph）的频域变换，就可以推导出图的卷积计算</td></tr></tbody></table></div><h4 id="空域图卷积"><a href="#空域图卷积" class="headerlink" title="空域图卷积"></a>空域图卷积</h4><ul><li>不依靠图谱卷积理论，直接在空间上定义卷积操作（有点CNN那味儿了）</li><li>定义直观，灵活性强</li></ul><p>本周主要了解的是谱域卷积。</p><h2 id="发展"><a href="#发展" class="headerlink" title="发展"></a>发展</h2><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200806105645321.png" alt="在这里插入图片描述"></p><p><center><b><font size ='2'>Fig1.发展时间线</font></b></center>&lt;/font&gt;<br>上图时间轴中，红色的是谱域卷积，蓝色的是空域卷积。</p><h1 id="重要的结论"><a href="#重要的结论" class="headerlink" title="重要的结论"></a>重要的结论</h1><p>ChebNet到GCN的转变是重点。<br>因为推导过程有点复杂，在此只介绍结论：<br>| 符号                   | 定义                                   |<br>| ——————————— | ——————————————————— |<br>| $L=D-A$                | 分别是拉普拉斯矩阵、度矩阵、邻接矩阵   |<br>| $U$                    | 拉普拉斯矩阵的特征向量（特征分解得到） |<br>| $\boldsymbol{\Lambda}$ | 拉普拉斯矩阵的特征值（特征分解得到）   |<br>| $\hat{X}$              | 傅里叶变换结果                         |</p><ul><li>结论一：<br>经过一系列复杂证明，我们可以知道Laplacian Matrix 的特征向量$U=(\bar{u}_1,\bar{u}_2,\bar{u}_3,…,\bar{u}_n,)$是n维空间的n个线性无关的正交向量。$U$可以构成一组正交基，且任意信号都可以由此基表示。</li><li>结论二：<br>$U$（拉普拉斯矩阵的特征向量）担任了基函数的位置；拉普拉斯矩阵的特征值担任了频率的位置。</li></ul><p>由此二结论，可以推导拓展到谱域的傅里叶变换：<br>Fourier transform ：$\hat{X}=U^TX$<br>Inverse Fourier transform : $X=U\hat{X}$</p><p>由此定义了图卷积：</p><script type="math/tex; mode=display">X*_G g = \mathcal{F^{-1}( \mathcal{F}(x)\odot\mathcal{F}(g))}=U(U^Tx\odot U^Tg)</script><p>其中，$\odot$是hamand积。</p><h1 id="从ChebNet-到GCN"><a href="#从ChebNet-到GCN" class="headerlink" title="从ChebNet 到GCN"></a>从ChebNet 到GCN</h1><p>因为按上式计算，每次都要进行特征值分解，计算量很大。所以使用Chebyshev（切比雪夫）多项式代替谱域的卷积核：</p><blockquote><p>详见:Convolutional neural networks on graphs with fast localized spectral filtering 一文 </p><p>$g<em>{\theta}=diag(U^Tg)$ ——-&gt;$g</em>{\theta}(\boldsymbol{\Lambda})=\sum^R_{k=0}\beta_kT_k \hat{(\boldsymbol{\Lambda}})$</p></blockquote><p>此方法有以下特点：<br>1）卷积核只有K+1个可学习的参数，一般 K远小于n，参数的复杂度被大大降低<br>2）采用Chebyshev多项式代替谱域的卷积核后，经过公示推导，ChebNet不需要对拉普拉斯矩阵做特征分解了。省略了最耗时的步骤。<br>3）卷积核具有严格的空间局部性。同时，K就是卷积核的“感受野半径”。即将中心顶点K阶近邻节点作为邻域节点。</p><p>关键在于GCN丢ChebNet进行了进一步的简化，它仅考虑一阶的ChebNet,得到一个非常简洁的表达式：</p><script type="math/tex; mode=display">x*_G g_\theta=\theta(I_N+D^{-1/2}AD^{-1/2})x</script><blockquote><p>详见 Semi-Supervised Classification With Graph Convolutional Networks 一文</p></blockquote><div class="table-container"><table><thead><tr><th>符号</th><th>定义</th></tr></thead><tbody><tr><td>$I_N$</td><td>单位矩阵</td></tr><tr><td>$D$、$A$</td><td>度矩阵、邻接矩阵</td></tr><tr><td>$\theta$</td><td>可学习参数</td></tr></tbody></table></div><p>现在还有一个问题，$I_N+D^{-1/2}AD^{-1/2}$的特征值范围[0,2]，在训练过程中可能会出现梯度消失或梯度爆炸，所以要进行归一化：</p><script type="math/tex; mode=display">Z = \tilde{D}^{-1/2} \tilde{A}\tilde{D}^{-1/2} X\Theta</script><p>这就是最终的表达式。其中符号$\tilde{D}=\sum<em>j \tilde{A}</em>{ij}$，$\tilde{A}=A+I_N$(可以理解为再归一化的邻接矩阵和度矩阵)</p><h1 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h1><p>在Semi-Supervised Classification With Graph Convolutional Networks一文中，提出一个具有两层的GCN模型：</p><script type="math/tex; mode=display">Z=f(X,A)=softmax(\tilde{A} ReLU（\tilde{A}XW^0）W^1)</script><p>其中$X$是节点特征矩阵，A是邻接矩阵。此GCN模型可以在很少的节点具有标签的情况下，完成节点的分类。</p><h1 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h1><ol><li>谱域图卷积不能做有向图（无法特征分解）</li><li>模型训练期间，图结构不能变</li><li>复杂度问题</li><li>层数太高会出现Over-Smoothing现象</li></ol><h1 id="TODO-LIST"><a href="#TODO-LIST" class="headerlink" title="TODO LIST"></a>TODO LIST</h1><p>空域图卷积</p><ul><li><p>GNN</p><ul><li>构建邻域（Random Walk）</li><li><p>对邻域节点进行内积</p><blockquote><p>详见：A Generalization of Convolutional Neural Networks to Graph-Structured Data</p></blockquote></li></ul></li><li><p>GraphSAGE</p><ul><li><p>卷积=采样+信息聚合</p><blockquote><p>详见:Inductive representation learning on large graphs</p></blockquote></li></ul></li><li><p>GAT</p><ul><li><p>卷积定义为利用注意力机制对邻域节点有区别的聚合</p><blockquote><p>详见：GRAPH ATTENTION NETWORKS</p></blockquote></li></ul></li><li><p>PGC</p><ul><li><p>卷积认为是特定的取样函数与特定的权重函数相乘后求和</p><blockquote><p>详见：Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action</p></blockquote></li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>Paper Reading</category>
      
      <category>Graph Convolutional Network</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>树莓派+Git——GitPi启动（树莓派搭建git服务器）并解决git bash中文英文乱码的问题</title>
    <link href="/2021/12/04/spi-git/"/>
    <url>/2021/12/04/spi-git/</url>
    
    <content type="html"><![CDATA[<h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><ol><li>装好系统的树莓派</li><li>win10+git</li></ol><h1 id="树莓派安装git"><a href="#树莓派安装git" class="headerlink" title="树莓派安装git"></a>树莓派安装git</h1><p>在树莓派的命令行中输入以下安装Git：<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">sudo apt-get install wget git-core<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>（如果没安装的话）安装ssh：<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">sudo apt-get install ssh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>设置自启动ssh：<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">sudo &#x2F;etc&#x2F;init.d&#x2F;ssh startsudo update-rc.d ssh defaults<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></p><h1 id="添加用户和组"><a href="#添加用户和组" class="headerlink" title="添加用户和组"></a>添加用户和组</h1><p>会在树莓派/home下创建一个git文件夹，用作储存。<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">adduser --system --shell &#x2F;bin&#x2F;bash --gecos &#39;git version control by pi&#39; --group --home &#x2F;home&#x2F;git git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>如果想要更换目录，请更改”/home/git”<br>然后更改git用户的密码，以后每次上传都需要使用：<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">passwd git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br><del>当然，如果想要删除git用户，使用</del><br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">userdel git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>这个时候，可以通过文件管理器查看树莓派/home中多了一个git空文件夹。<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200810110631578.png" alt="在这里插入图片描述"></p><h1 id="创建新的仓库并初始化"><a href="#创建新的仓库并初始化" class="headerlink" title="创建新的仓库并初始化"></a>创建新的仓库并初始化</h1><p>正式开始，我们需要先在树莓派上创建一个新的仓库。这就是管理我们代码的地方。<br>首先，先进入/home/git 路径：<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">cd &#x2F;home&#x2F;git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>切换至创建的git用户:<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">su git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>会提醒输入password，输入之前修改的密码后，成功切换用户。<br>创建一个新的仓库：<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">mkdir test.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>创建后需要进入仓库（否则初始化的是git文件夹）：<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">cd test.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>初始化仓库：<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">git --bare init<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200810111257618.png" alt="在这里插入图片描述"><br>树莓派上的操作全部完成，可以打开test.git看到里面多了一堆东西<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200810111347786.png" alt="在这里插入图片描述"></p><h1 id="在win10上上传文件至远程仓库"><a href="#在win10上上传文件至远程仓库" class="headerlink" title="在win10上上传文件至远程仓库"></a>在win10上上传文件至远程仓库</h1><p>对于我们的PC而言，树莓派的仓库就相当于一个远程仓库。（树莓派和PC必须要连接同一网络）<br>在想要保存文件的路径下（此处我放在桌面）鼠标右击，点击git bash here，打开git bash<br>先将我们创建的远程仓库clone下来：<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">git clone git@192.168.0.106:&#x2F;home&#x2F;git&#x2F;test.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>（此处我的树莓派ip地址是192.168.0.106；我们要clone的仓库是之前创建的位于/home/git下的test.git）<br>输入密码后会提醒clone了一个空仓库<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200810111947936.png" alt="在这里插入图片描述"><br>看桌面也发现多了一个test文件夹，就是我们的仓库。<br>然后打开桌面上的文件夹，增加修改。为了演示方便，我增加了一个名为“中文测试.txt”的文件。<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/202008101121278.png" alt="在这里插入图片描述"><br>然后和正常上传文件的方法一样，git bash 进入test文件夹。<br>然后添加所有文件<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">git add .<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>提交修改进暂存区：<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">git commit -m &quot;上传了一个中文名的文件&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>提交至远程仓库：<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">git push origin master<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>没有意外的话就提交成功了！<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200810112438991.png" alt="在这里插入图片描述"><br>我们再测试一下提交的成果。先退出test文件夹，删除test文件夹，并再次clone<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/2020081011261574.png" alt="在这里插入图片描述"><br>再在桌面打开test文件夹，发现确实是我们修改后的文件！<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200810112701796.png" alt="在这里插入图片描述"><br>再在git bash 中查询记录：<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">git log <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>(我的自定义了log-&gt;lg，所以我的是git lg)<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200810112837354.png" alt="在这里插入图片描述"><br>完美！！</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol><li>先在树莓派创建用户和仓库。并初始化。后续使用只需要创建仓库即可，不需要重复创建用户（会告诉你用户已存在）。</li><li>在电脑上clone创建的远程仓库，并修改后，正常提交即可。</li></ol><h1 id="可能遇到的问题"><a href="#可能遇到的问题" class="headerlink" title="可能遇到的问题"></a>可能遇到的问题</h1><ol><li><p>在git bash中可能出现英文乱码的情况。<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200810113458404.png" alt="在这里插入图片描述"><br>测试了一下上传github没有问题，说明是树莓派的文字编码有问题，于是我把树莓派的文字显示改回了英文，修复了该问题。<br>在树莓派命令行中：</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">sudo nano&#x2F;etc&#x2F;default&#x2F;locale <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>将原来的配置内容修改为：</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">LANG&#x3D;zh_CN.UTF-8LANGUAGE&#x3D;en_US:en<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><p>（ctrl+X保存并退出）再</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">locale-gen -en_US:en<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>重启树莓派即可生效。</p></li><li><p>git bash 在提交文件时，如果文件中有中文，可能出现乱码。<br>测试了GitHub也有这样的现象，说明是win10的问题。正常而言<a href="https://zhuanlan.zhihu.com/p/91741156">参考知乎</a>即可解决。如果和我一样还是无法解决的，问题可能在于win10默认的中文编码方式是GKB，而更国际化的是utf-8，修改win10中文编码为utf-8即可。<img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200810114350471.png" alt="在这里插入图片描述"><br>①打开语言中的 管理语言设置<br>②点击 更改系统区域设置<br>③勾选beta版<br>④确定 并重启电脑 完成！</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>gadget</category>
      
      <category>Raspberry Pi</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RaspberryPi</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>树莓派启动——安装+无显示器使用+自启动VNC</title>
    <link href="/2021/12/04/spi-start/"/>
    <url>/2021/12/04/spi-start/</url>
    
    <content type="html"><![CDATA[<p>时隔一年多，拿起树莓派却忘记如何使用了。本想用作自己搭建git服务器，后续再完成了。在此记录一下使用流程。</p><h2 id="硬件准备"><a href="#硬件准备" class="headerlink" title="硬件准备"></a>硬件准备</h2><ol><li>树莓派(3b+)</li><li>TF卡和读卡器（16-256GB，但不要太大，SD卡格式化要很久。我是32GB）</li><li>网线</li><li>电源线</li></ol><h2 id="软件准备"><a href="#软件准备" class="headerlink" title="软件准备"></a>软件准备</h2><p>（<a href="https://shumeipai.nxez.com/download#tools">至树莓派实验室下载</a>）:</p><ol><li>SD卡格式化工具 SD Formatter</li><li>镜像烧录工具 Win32DiskImager</li><li>SSH工具 PUTTY</li><li><a href="https://www.raspberrypi.org/downloads/raspberry-pi-os/">树莓派os官网下载</a> </li><li>VNCviewer</li></ol><h2 id="写入系统"><a href="#写入系统" class="headerlink" title="写入系统"></a>写入系统</h2><ol><li><p>使用SD Formatter格式化TF卡<img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/2020080916412384.png" alt="在这里插入图片描述"><br>（格式化会有点久）<br>2.解压官网下载的操作系统，得到.img 文件。打开Win32DiskImager，在①中选择解压得到的.img文件；在②中选择自己的TF卡；点击③。系统烧录完成！！<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200809164521285.png" alt="在这里插入图片描述"></p><h2 id="启动树莓派"><a href="#启动树莓派" class="headerlink" title="启动树莓派"></a>启动树莓派</h2></li><li><p>首先电脑打开TF卡，创建一个名为ssh的空白文件（没有后缀）</p></li><li>TF卡插入树莓派，并通电。此时树莓派已启动。但由于没有多余的显示器，不能看到图形界面。</li><li>用网线链接电脑和树莓派。</li><li>在wlan属性中设置internet共享<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200809165043538.png" alt="在这里插入图片描述"></li><li>然后查询树莓派ip地址：<br> 通过cmd输入 arp -a，查看 b8-开头的ip就是树莓派ip。<img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200809165641164.png" alt="在这里插入图片描述"></li><li>打开putty。输入ip地址打开。默认账号为:pi，默认密码为：raspberry。完成！<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200809165959464.png" alt="在这里插入图片描述"></li><li><p>为了看到图形界面，启动树莓派的vncserver，即在命令行中输入：</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">vncserver<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200809170309463.png" alt="在这里插入图片描述"></p></li><li><p>打开VNCviewer，输入ip地址和账号密码，即可看到图形界面了！</p></li></ol><h2 id="换源"><a href="#换源" class="headerlink" title="换源"></a>换源</h2><ol><li>在terminal中输入：<div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">sudo nano &#x2F;etc&#x2F;apt&#x2F;sources.list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></li><li>注释掉源文件中的内容，更换为阿里源：<div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">deb http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;raspbian&#x2F;raspbian&#x2F; stretch main contrib non-free rpideb-src http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;raspbian&#x2F;raspbian&#x2F; stretch main contrib non-free rpi<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></li><li>打开并编辑/etc/apt/sources.list.d/raspi.list文件<div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">sudo nano &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;raspi.list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></li><li>注释掉源文件内容，更换为：<div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">deb http:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;archive.raspberrypi.org&#x2F;debian&#x2F; stretch main uideb-src http:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;archive.raspberrypi.org&#x2F;debian&#x2F; stretch main ui<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></li><li>更新软件源列表<div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">sudo apt-get update<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><h2 id="VNC自启动"><a href="#VNC自启动" class="headerlink" title="VNC自启动"></a>VNC自启动</h2>为了下次使用方便，首先将树莓派脸上wifi。通过图形界面右上角打开WiFi，并连接：<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200809170824182.png" alt="在这里插入图片描述"><br>然后记一下树莓派所分得的ip地址，并拔掉网线。拔掉网线后会断开vnc。因为现在的ip地址变了。<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200809171006256.png" alt="在这里插入图片描述"><br>如果没有看ip地址就断开了</li></ol><ul><li>可以使用arp -a查询b8开头的ip地址</li><li>可以通过路由器管理设备查询（192.168.0.1 or 192.168.1.1）</li></ul><p>现在只要启动树莓派 并启动vncserver，就可以通过vncviewer查看图形界面了。</p><p>现在的问题是如何开机自启vncserver？</p><ol><li>打开terminal，输入以下打开设置<div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">sudo raspi-config<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></li><li>选择Interfacing Options-&gt;VNC-&gt;选择yes  等待完成</li><li>打开初始化文件<div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">sudo vim &#x2F;etc&#x2F;init.d&#x2F;vncserver<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div>并粘贴以下内容,粘贴后 按 ctrl+X 保存并退出:<div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">#!&#x2F;bin&#x2F;sh### BEGIN INIT INFO# Provides: vncserver# Required-Start: $local_fs# Required-Stop: $local_fs# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: Start&#x2F;stop vncserver### END INIT INFO# More details see:# http:&#x2F;&#x2F;www.penguintutor.com&#x2F;linux&#x2F;vnc### Customize this entry# Set the USER variable to the name of the user to start vncserver underexport USER&#x3D;&#39;pi&#39;### End customization requiredeval cd ~$USERcase &quot;$1&quot; instart)# 启动命令行。此处自定义分辨率、控制台号码或其它参数。su $USER -c &#39;&#x2F;usr&#x2F;bin&#x2F;vncserver -depth 16 -geometry 1920x1200 :1&#39;echo &quot;Starting VNC server for $USER &quot;;;stop)# 终止命令行。此处控制台号码与启动一致。su $USER -c &#39;&#x2F;usr&#x2F;bin&#x2F;vncserver -kill :1&#39;echo &quot;vncserver stopped&quot;;;*)echo &quot;Usage: &#x2F;etc&#x2F;init.d&#x2F;vncserver &#123;start|stop&#125;&quot;exit 1;;esacexit 0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></li><li>修改权限<div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">sudo chmod 755 &#x2F;etc&#x2F;init.d&#x2F;vncserver<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></li><li>添加开机启动项<div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">sudo update-rc.d vncserver defaults<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></li><li>重启树莓派<div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">sudo reboot<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></li></ol><p>至此全部完成</p>]]></content>
    
    
    <categories>
      
      <category>gadget</category>
      
      <category>Raspberry Pi</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RaspberryPi</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>安装Anaconda+pytorch+pycharm配置，并创建新的环境</title>
    <link href="/2021/12/04/pythonenvs3/"/>
    <url>/2021/12/04/pythonenvs3/</url>
    
    <content type="html"><![CDATA[<h1 id="提前准备"><a href="#提前准备" class="headerlink" title="提前准备"></a>提前准备</h1><p>检查一下系统是否已经安装了python，建议删除，不然容易遇到一些奇怪的问题。<br>如果需要卸载已有的python，先查询自己python版本，再下次相同版本，点击运行时选择uninstall即可。<br>如果想完全卸载anaconda，参考<a href="https://blog.csdn.net/kuweicai/article/details/90145242">如何彻底的卸载anaconda（包括配置文件）</a></p><h1 id="下载并安装Anaconda"><a href="#下载并安装Anaconda" class="headerlink" title="下载并安装Anaconda"></a>下载并安装Anaconda</h1><h2 id="下载Anaconda"><a href="#下载Anaconda" class="headerlink" title="下载Anaconda"></a>下载Anaconda</h2><p>   直接<a href="https://www.anaconda.com/products/individual">官网下载</a>.</p><h2 id="安装Anaconda"><a href="#安装Anaconda" class="headerlink" title="安装Anaconda"></a>安装Anaconda</h2><p>  傻瓜式安装一路next。值得注意的是：<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200730171324257.png" alt="选择是否添加路径"><br>此处的路径不添加也可，后面在环境变量手动加。<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/202007301712511.png" alt="了解更多"><br>此处两个勾都去掉。</p><p>安装完成后，如果添加了环境变量anaconda安装就完成了，没有添加的话：</p><p>1.win + S 输入 环境变量，打开系统环境变量中的path变量<br>2.根据自己anaconda安装路径添加：<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200730174738575.png" alt="根据自己路径添加环境变量"></p><p>Anaconda安装完成！可以使用 win+R 打开cmd ，输入python检查是否安装完成。<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/2020073018183797.png" alt="在这里插入图片描述"></p><h2 id="换国内镜像源"><a href="#换国内镜像源" class="headerlink" title="换国内镜像源"></a>换国内镜像源</h2><p>然后换清华的源（不然下载库会很慢）</p><p>1.win + R  输入:<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">%HOMEPATH%<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200730172715491.png" alt="在这里插入图片描述"><br>2.进入路径，打开.condarc<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200730172743361.png" alt="在这里插入图片描述"><br>3.修改为如下即可：<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">channels:  - http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;free&#x2F;  - http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud&#x2F;conda-forge&#x2F;  - http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud&#x2F;msys2&#x2F;  - http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud&#x2F;bioconda&#x2F;  - http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;main&#x2F;  - http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud&#x2F;pytorch&#x2F;  - http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud&#x2F;peterjc123&#x2F;show_channel_urls: truessl_verify: true<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><br>没有.condarc文件的话，先在cmd中输入</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">conda config --add channels http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;free&#x2F;conda config --add channels http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud&#x2F;conda-forgeconda config --add channels http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud&#x2F;msys2&#x2F;conda config --set show_channel_urls yes<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div><p>也可以生成.condarc文件并换源</p><h2 id="创建新环境"><a href="#创建新环境" class="headerlink" title="创建新环境"></a>创建新环境</h2><p>方法一：<br>    可以通过打开Anaconda Navigator —&gt;Enviroments—&gt;Create 来创建新环境<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200730180857607.png" alt="创建新环境方法1"><br>方法二（个人推荐）：<br>使用 Anaconda Prompt （win + s 搜索），输入：</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">conda create -n xxxxx python&#x3D;?? anaconda<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>其中xxxxx是自己想创建的环境名 ；??是python版本号，如下图<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200730181423527.png" alt=""><br>可以看到一堆要安装的包。如果不想安装这么多，可以创建一个只有最基本包的环境，和上面命令大致一样，只是不要最后的 anaconda ：<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">conda create -n xxxxx python&#x3D;??<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>因为换了源，所以这一步应该比较快。完成后可以在Anaconda Prompt中检查：<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">activate xxxxx<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200730182210831.png" alt="在这里插入图片描述"><br>可以看到前缀由（base）变成了（xxxxx），base是anaconda自带的，xxxxx是刚刚创建的。我创建的名字是pytorch。</p><h1 id="安装Pytorch"><a href="#安装Pytorch" class="headerlink" title="安装Pytorch"></a>安装Pytorch</h1><p>依然<a href="https://pytorch.org/">官网下载</a><br>然后根据自己的需要选择pytorch版本<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200730182712563.png" alt="在这里插入图片描述"><br>然后复制官网生成的  Run this Command：<br><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">conda install pytorch torchvision cudatoolkit&#x3D;10.2 pytorch<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>注意，这行代码去掉了 -c，是因为去掉后才会从清华的源上下载。<br>打开 Anaconda Prompt ，并激活需要安装pytorch的环境。我安装在刚刚生成的pytorch环境中。<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200730183025287.png" alt="在这里插入图片描述"><br>安装pytorch完成。</p><p>这里可能还会遇到两个问题：<br>问题一：<br>如果pytorch安装在自己创建的环境中，例如我安装在了名为pytorch的环境中，需要重新设置环境变量：<img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200730183300706.png" alt="重新设置环境变量"><br>问题二：<br>python pycharm 和anaconda的库版本可能不合。<br>我的pytorch环境中python是3.7.8，而numpy是1.19.0。建议降低numpy的版本。在Anaconda Prompt中切换到需要更改的环境，输入：<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200730183727188.png" alt="在这里插入图片描述"><br>等待完成即可。<br>到此完成了pytorch安装</p><h1 id="pycharm配置"><a href="#pycharm配置" class="headerlink" title="pycharm配置"></a>pycharm配置</h1><p>安装就懒得写了。<br>在创建项目时，选择Existing interpreter：<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200730184208253.png" alt="在这里插入图片描述"><br>点击Existing interpreter旁边的三个点展开选择。<br>再按顺序选择即可<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200730184457273.png" alt="在这里插入图片描述"><br>此处的路径是安装anaconda的路径。如果选择的是base环境，python.exe的位置就在安装路径下；如果选择自己创建的环境，python.exe在。…(安装路径)\envs\xxxxx（自己创建的环境名）</p><p>完成！！！</p>]]></content>
    
    
    <categories>
      
      <category>envs</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Deep Learning</tag>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pytorch的自定义数据集/DataLoader和Dataset重写</title>
    <link href="/2021/12/04/datasetloader/"/>
    <url>/2021/12/04/datasetloader/</url>
    
    <content type="html"><![CDATA[<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h1><p>&emsp;&emsp;做Modulation Recognition的时候需要加载自定义的数据集，这就涉及到DataLoader和Dataset类中的方法重写了。</p><h1 id="DataLoader介绍"><a href="#DataLoader介绍" class="headerlink" title="DataLoader介绍"></a>DataLoader介绍</h1><p>&emsp;&emsp;源码中的介绍是：<br><div class="code-wrapper"><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token operator">*</span><span class="token class-name">Data</span> <span class="token class-name"><span class="token namespace">loader<span class="token punctuation">.</span></span> Combines</span> a dataset and a sampler<span class="token punctuation">,</span> and <span class="token keyword">provides</span> <span class="token namespace">an</span> iterable over the given dataset<span class="token punctuation">.</span>*<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>&emsp;&emsp;也就是说，我们可以通过输入一个数据集，及常用参数如：batch_size、shuffle,就可以得到一个打包好的迭代器。这个迭代器包含了batch_size的序号及根据batch_size分割好的数据块。</p><h1 id="Dataset-介绍"><a href="#Dataset-介绍" class="headerlink" title="Dataset 介绍"></a>Dataset 介绍</h1><p>&emsp;&emsp;源码中的介绍是：<br><div class="code-wrapper"><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">An</span> <span class="token keyword">abstract</span> <span class="token keyword">class</span> representing a <span class="token operator">:</span><span class="token keyword">class</span><span class="token operator">:</span>`<span class="token class-name">Dataset</span>`<span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>&emsp;&emsp;很短，但是很经典。这是一个抽象类。所谓抽象类就是类的抽象化，而类本身就是不存在的，所以抽象类无法实例化。它存在的意义就是被继承。而且继承抽象类的类必须要重写抽象类的方法。<br>&emsp;&emsp;简单的说，我们构造一个MyDataset数据类，需要继承Dataset，并重写Dataset中的方法。</p><p>&emsp;&emsp;去掉源码中的注释，Dataset抽象类的定义就五行代码，两个方法：<br><div class="code-wrapper"><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">class</span> <span class="token class-name">Dataset</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token operator">:</span>    def <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token operator">:</span>        raise <span class="token class-name">NotImplementedError</span>    def <span class="token function">__add__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> other<span class="token punctuation">)</span><span class="token operator">:</span>        <span class="token keyword">return</span> <span class="token class-name">ConcatDataset</span><span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">,</span> other<span class="token punctuation">]</span><span class="token punctuation">)</span>            # <span class="token class-name">No</span> `def <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span>` <span class="token keyword">default</span><span class="token operator">?</span>    # <span class="token class-name">See</span> NOTE <span class="token punctuation">[</span> <span class="token class-name">Lack</span> of <span class="token class-name">Default</span> `__len__` in <span class="token class-name">Python</span> <span class="token class-name">Abstract</span> <span class="token class-name">Base</span> <span class="token class-name">Classes</span> <span class="token punctuation">]</span>    # in pytorch<span class="token operator">/</span>torch<span class="token operator">/</span>utils<span class="token operator">/</span>data<span class="token operator">/</span>sampler<span class="token punctuation">.</span>py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><br>&emsp;&emsp;根据我们的需要，我们会重写  <strong>getitem</strong>方法，以及<strong>len</strong>方法。</p><h1 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h1><p>&emsp;&emsp;首先，我们要定义自己的数据集类，例如叫做MyDataset，则代码片段应该为：<br><div class="code-wrapper"><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">class</span> <span class="token class-name">MyDataSet</span><span class="token punctuation">(</span><span class="token class-name">Dataset</span><span class="token punctuation">)</span><span class="token operator">:</span>    def <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">,</span> label<span class="token punctuation">)</span><span class="token operator">:</span>        self<span class="token punctuation">.</span>data <span class="token operator">=</span> data        self<span class="token punctuation">.</span>label <span class="token operator">=</span> label        self<span class="token punctuation">.</span>length <span class="token operator">=</span> data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>            def <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> mask<span class="token punctuation">)</span><span class="token operator">:</span>        label <span class="token operator">=</span> self<span class="token punctuation">.</span>label<span class="token punctuation">[</span>mask<span class="token punctuation">]</span>        data <span class="token operator">=</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>mask<span class="token punctuation">]</span>        <span class="token keyword">return</span> label<span class="token punctuation">,</span> data    def <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token operator">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>length<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></p><h2 id="继承"><a href="#继承" class="headerlink" title="继承"></a>继承</h2><p>&emsp;&emsp;很简单<br><div class="code-wrapper"><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">class</span> <span class="token class-name">MyDataSet</span><span class="token punctuation">(</span><span class="token class-name">Dataset</span><span class="token punctuation">)</span><span class="token operator">:</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>&emsp;&emsp;表示我们MyDataSet类继承了抽象类Dataset。该MyDataSet类中的有三个方法。</p><h2 id="init方法"><a href="#init方法" class="headerlink" title="init方法"></a><strong>init</strong>方法</h2><p>&emsp;&emsp;<strong>init</strong>方法是python中的构造方法(java中是叫构造方法，不知道python是不是这么叫，如果不是请大家指正)，构造方法会在实例化对象时调用。其传入参数就是我们的==数据集==(data)和==标签集==(label)。<br><div class="code-wrapper"><pre class="line-numbers language-java" data-language="java"><code class="language-java">def <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">,</span> label<span class="token punctuation">)</span><span class="token operator">:</span>       self<span class="token punctuation">.</span>data <span class="token operator">=</span> data       self<span class="token punctuation">.</span>label <span class="token operator">=</span> label       self<span class="token punctuation">.</span>length <span class="token operator">=</span> data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div></p><h2 id="getitem方法"><a href="#getitem方法" class="headerlink" title="getitem方法"></a><strong>getitem</strong>方法</h2><p>&emsp;&emsp;<strong>getitem</strong>方法是获取返回数据的方法，传入参数是一个index，也被叫做mask，就是我们对数据集的选择索引。在自己使用时，比如想从data = [100, 99, 98, …, 0]的集合中选出下标为[0, 2, 4]的集合，则index/mask 就取[0, 2, 4],返回data[index]即可。<br>&emsp;&emsp;其实在调用DataLoader时就会自己生成index，所以我们只需要写好方法即可。<br><div class="code-wrapper"><pre class="line-numbers language-java" data-language="java"><code class="language-java">def <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> mask<span class="token punctuation">)</span><span class="token operator">:</span>       <span class="token keyword">return</span> self<span class="token punctuation">.</span>label<span class="token punctuation">[</span>mask<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>mask<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></p><h2 id="len方法"><a href="#len方法" class="headerlink" title="len方法"></a><strong>len</strong>方法</h2><p>&emsp;&emsp;偷了个懒没有去看源码。听说不给返回length的话pytorch会一脸xx。<br><div class="code-wrapper"><pre class="line-numbers language-java" data-language="java"><code class="language-java">def <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token operator">:</span>       <span class="token keyword">return</span> self<span class="token punctuation">.</span>length<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></p><h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><p>&emsp;&emsp;完成了MyDataSet，就可以通过DataLoader使用了。例如此处我已经有了一个X<em>train,其中的数据的每一个batch都代表了一个信号。Y<em>train当中都是X_train对应的标签。<br>&emsp;&emsp;于是我的代码就是：<br><div class="code-wrapper"><pre class="line-numbers language-java" data-language="java"><code class="language-java">train_set <span class="token operator">=</span> <span class="token class-name">MyDataSet</span><span class="token punctuation">(</span>data<span class="token operator">=</span><span class="token class-name">X_train</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token class-name">Y_train</span><span class="token punctuation">)</span>num_epoch <span class="token operator">=</span> <span class="token number">100</span>     # number of epochs <span class="token keyword">to</span> <span class="token namespace">train</span> onbatch_size <span class="token operator">=</span> <span class="token number">1024</span>  # training batch sizetrain_data <span class="token operator">=</span> <span class="token class-name">DataLoader</span><span class="token punctuation">(</span>train_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token class-name">True</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch in <span class="token function">range</span><span class="token punctuation">(</span>num_epoch <span class="token punctuation">)</span><span class="token operator">:</span>    model<span class="token punctuation">.</span><span class="token function">train</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> batchsz<span class="token punctuation">,</span> <span class="token punctuation">(</span>label<span class="token punctuation">,</span> data<span class="token punctuation">)</span> in <span class="token function">enumerate</span><span class="token punctuation">(</span>train_data<span class="token punctuation">)</span><span class="token operator">:</span>        # i表示第几个batch， data表示该batch对应的数据，包含data和对应的labels        <span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"第 &#123;&#125; 个Batch size of label &#123;&#125; and size of data&#123;&#125;"</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>batchsz<span class="token punctuation">,</span> label<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><br>&emsp;&emsp;DataLoader会根据设置的batch_size来产生index/mask，然后调用Datase的__getitem</em></em>方法取出数据。<br>&emsp;&emsp;输出结果如下：<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20200919225212630.png" alt="在这里插入图片描述"><br>&emsp;&emsp;接下来就可以愉快的写模型了！！！</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>&emsp;&emsp;其实看起来很简单的一个Dataset抽象类重写和DataLoader使用，包含了面向对象编程的三大特点：==封装==、==继承==、==多态==。</p><ul><li>封装体现在Dataset抽象类的封装及我们的MyDataSet类的封装上。</li><li>继承体现在我们MyDataSet继承Dataset抽象类上。</li><li><del>多态体现在DataLoader对数据集的操作上</del>（这点纯属个人理解，感觉有点像java中的向上转型，但python好像没有这一概念）。</li></ul>]]></content>
    
    
    <categories>
      
      <category>utils</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>utils</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>latex工具箱</title>
    <link href="/2021/12/04/latexutils/"/>
    <url>/2021/12/04/latexutils/</url>
    
    <content type="html"><![CDATA[<h1 id="行间公式"><a href="#行间公式" class="headerlink" title="行间公式"></a>行间公式</h1><div class="code-wrapper"><pre class="line-numbers language-latex" data-language="latex"><code class="language-latex"><span class="token function selector">\begin</span><span class="token punctuation">&#123;</span><span class="token keyword">equation</span><span class="token punctuation">&#125;</span><span class="token equation string"><span class="token equation-command regex">\begin</span>&#123;aligned&#125;    <span class="token equation-command regex">\mathcal</span>&#123;L&#125;_&#123;dif&#125; =&amp; H(f_&#123;<span class="token equation-command regex">\theta</span>_1&#125;(x),f_&#123;<span class="token equation-command regex">\theta</span>_2&#125;(g_1(x)))<span class="token equation-command regex">\\</span>+&amp;H(f_&#123;<span class="token equation-command regex">\theta</span>_2&#125;(x),f_&#123;<span class="token equation-command regex">\theta</span>_1&#125;(g_2(x)))<span class="token equation-command regex">\label</span>&#123;eqn:5&#125;<span class="token equation-command regex">\end</span>&#123;aligned&#125;</span><span class="token function selector">\end</span><span class="token punctuation">&#123;</span><span class="token keyword">equation</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h1 id="插入图片（矢量图推荐-eps）"><a href="#插入图片（矢量图推荐-eps）" class="headerlink" title="插入图片（矢量图推荐.eps）"></a>插入图片（矢量图推荐.eps）</h1><p>python直接保存的svg可以，但visio画的有时候不行，先转pdf再用inkscape转为.eps文件导入。<br>插入eps矢量图先导入两个包<br><div class="code-wrapper"><pre class="line-numbers language-latex" data-language="latex"><code class="language-latex"><span class="token function selector">\usepackage</span><span class="token punctuation">&#123;</span><span class="token keyword">graphicx</span><span class="token punctuation">&#125;</span> <span class="token comment">%use graph format</span><span class="token function selector">\usepackage</span><span class="token punctuation">&#123;</span><span class="token keyword">epstopdf</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><br>然后正常的插图图像<br><div class="code-wrapper"><pre class="line-numbers language-latex" data-language="latex"><code class="language-latex"><span class="token function selector">\begin</span><span class="token punctuation">&#123;</span><span class="token keyword">figure</span><span class="token punctuation">&#125;</span><span class="token punctuation">[</span>htbp<span class="token punctuation">&#125;</span><span class="token function selector">\centering</span><span class="token function selector">\includegraphics</span><span class="token punctuation">[</span>width=0.5<span class="token function selector">\textwidth</span><span class="token punctuation">]</span><span class="token punctuation">&#123;</span>pic/CLDNN.eps<span class="token punctuation">&#125;</span><span class="token comment">%宽度为页面的50%</span><span class="token function selector">\caption</span><span class="token punctuation">&#123;</span>CLDNN Network<span class="token punctuation">&#125;</span> <span class="token comment">%标注</span><span class="token function selector">\label</span><span class="token punctuation">&#123;</span><span class="token keyword">fig:cldnn</span><span class="token punctuation">&#125;</span><span class="token function selector">\end</span><span class="token punctuation">&#123;</span><span class="token keyword">figure</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></p><h1 id="IEEE-Conference-作者信息模板"><a href="#IEEE-Conference-作者信息模板" class="headerlink" title="IEEE Conference 作者信息模板"></a>IEEE Conference 作者信息模板</h1><div class="code-wrapper"><pre class="line-numbers language-latex" data-language="latex"><code class="language-latex"><span class="token function selector">\author</span><span class="token punctuation">&#123;</span><span class="token function selector">\IEEEauthorblockN</span><span class="token punctuation">&#123;</span>1<span class="token function selector">\textsuperscript</span><span class="token punctuation">&#123;</span>st<span class="token punctuation">&#125;</span> Name1<span class="token punctuation">&#125;</span><span class="token function selector">\IEEEauthorblockA</span><span class="token punctuation">&#123;</span><span class="token function selector">\textit</span><span class="token punctuation">&#123;</span>xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx<span class="token punctuation">&#125;</span> <span class="token function selector">\\</span>Chengdu, China <span class="token function selector">\\</span>xxxxx@qq.com<span class="token punctuation">&#125;</span><span class="token function selector">\and</span><span class="token function selector">\IEEEauthorblockN</span><span class="token punctuation">&#123;</span>2<span class="token function selector">\textsuperscript</span><span class="token punctuation">&#123;</span>nd<span class="token punctuation">&#125;</span> Name2<span class="token punctuation">&#125;</span><span class="token function selector">\IEEEauthorblockA</span><span class="token punctuation">&#123;</span><span class="token function selector">\textit</span><span class="token punctuation">&#123;</span>xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx<span class="token punctuation">&#125;</span> <span class="token function selector">\\</span>Chengdu, China  <span class="token function selector">\\</span>xxxxx@qq.con<span class="token punctuation">&#125;</span><span class="token function selector">\and</span><span class="token function selector">\IEEEauthorblockN</span><span class="token punctuation">&#123;</span>3<span class="token function selector">\textsuperscript</span><span class="token punctuation">&#123;</span>st<span class="token punctuation">&#125;</span> Name3<span class="token punctuation">&#125;</span><span class="token function selector">\centerline</span>~  <span class="token comment">% 让第三个作者居中</span><span class="token function selector">\IEEEauthorblockA</span><span class="token punctuation">&#123;</span><span class="token function selector">\textit</span><span class="token punctuation">&#123;</span>xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx<span class="token punctuation">&#125;</span> <span class="token function selector">\\</span>Chengdu, China  <span class="token function selector">\\</span>xxxxx@qq.com<span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/2d320c1a614a4c919702e9c8c95790a2.png" alt="在这里插入图片描述"></p><h1 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h1><div class="code-wrapper"><pre class="line-numbers language-latex" data-language="latex"><code class="language-latex"><span class="token function selector">\renewcommand</span><span class="token punctuation">&#123;</span><span class="token function selector">\arraystretch</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#123;</span>1.3<span class="token punctuation">&#125;</span><span class="token comment">%调行距</span><span class="token comment">%\setlength\tabcolsep&#123;3pt&#125;%调列距</span><span class="token function selector">\begin</span><span class="token punctuation">&#123;</span><span class="token keyword">table</span><span class="token punctuation">&#125;</span><span class="token punctuation">[</span>htbp<span class="token punctuation">]</span><span class="token function selector">\caption</span><span class="token punctuation">&#123;</span>Comparison of method performance<span class="token punctuation">&#125;</span><span class="token function selector">\begin</span><span class="token punctuation">&#123;</span><span class="token keyword">center</span><span class="token punctuation">&#125;</span><span class="token function selector">\begin</span><span class="token punctuation">&#123;</span><span class="token keyword">tabular</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#123;</span>|c|c|c|<span class="token punctuation">&#125;</span><span class="token function selector">\hline</span><span class="token function selector">\textbf</span><span class="token punctuation">&#123;</span>Method<span class="token punctuation">&#125;</span><span class="token punctuation">&amp;</span><span class="token function selector">\textbf</span><span class="token punctuation">&#123;</span>Acc:10+500<span class="token punctuation">&#125;</span> <span class="token punctuation">&amp;</span><span class="token function selector">\textbf</span><span class="token punctuation">&#123;</span>Acc:50+500<span class="token punctuation">&#125;</span><span class="token function selector">\\</span><span class="token function selector">\hline</span>FixMatch<span class="token punctuation">&amp;</span>74.18\<span class="token comment">% &amp;83.53\%\\\hline</span>SSACGAN-FM<span class="token punctuation">&amp;</span>50.77\<span class="token comment">%&amp;71.00\%\\\hline</span>Enhanced DCT<span class="token punctuation">&amp;</span><span class="token function selector">\textbf</span><span class="token punctuation">&#123;</span>80.82<span class="token punctuation">&#125;</span>\<span class="token comment">%&amp;\textbf&#123;87.27&#125;\%\\\hline</span><span class="token function selector">\end</span><span class="token punctuation">&#123;</span><span class="token keyword">tabular</span><span class="token punctuation">&#125;</span><span class="token function selector">\label</span><span class="token punctuation">&#123;</span><span class="token keyword">tab:1</span><span class="token punctuation">&#125;</span><span class="token function selector">\end</span><span class="token punctuation">&#123;</span><span class="token keyword">center</span><span class="token punctuation">&#125;</span><span class="token function selector">\end</span><span class="token punctuation">&#123;</span><span class="token keyword">table</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h1 id="强制符号在下方"><a href="#强制符号在下方" class="headerlink" title="强制符号在下方"></a>强制符号在下方</h1><div class="code-wrapper"><pre class="line-numbers language-latex" data-language="latex"><code class="language-latex"><span class="token function selector">\sum</span><span class="token function selector">\limits</span>_<span class="token punctuation">&#123;</span>x=0<span class="token punctuation">&#125;</span>^1<span class="token function selector">\mathop</span><span class="token punctuation">&#123;</span><span class="token function selector">\mathbb</span><span class="token punctuation">&#123;</span>E<span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token function selector">\limits</span>_<span class="token punctuation">&#123;</span>X<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div><p>$\sum\limits_{x=0}^1$</p><p>$\mathop{\mathbb{E}}\limits_{X}$</p><h1 id="大括号公式"><a href="#大括号公式" class="headerlink" title="大括号公式"></a>大括号公式</h1><div class="code-wrapper"><pre class="line-numbers language-latex" data-language="latex"><code class="language-latex"><span class="token function selector">\lambda</span> (t)=<span class="token function selector">\left</span><span class="token function selector">\&#123;</span> <span class="token function selector">\begin</span><span class="token punctuation">&#123;</span><span class="token keyword">array</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#123;</span>l<span class="token punctuation">&#125;</span><span class="token function selector">\lambda</span> _<span class="token punctuation">&#123;</span>max<span class="token punctuation">&#125;</span>exp(-5(<span class="token function selector">\frac</span><span class="token punctuation">&#123;</span>t-T<span class="token punctuation">&#125;</span><span class="token punctuation">&#123;</span>80<span class="token punctuation">&#125;</span>)^2),<span class="token function selector">\quad</span> t<span class="token function selector">\le</span> T<span class="token function selector">\\</span><span class="token function selector">\lambda</span> _<span class="token punctuation">&#123;</span>max<span class="token punctuation">&#125;</span>,<span class="token function selector">\quad</span> t>T<span class="token function selector">\\</span><span class="token function selector">\end</span><span class="token punctuation">&#123;</span><span class="token keyword">array</span><span class="token punctuation">&#125;</span> <span class="token function selector">\right</span>. <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div><script type="math/tex; mode=display">\lambda (t)=\left\{ \begin{array}{l}    \lambda _{max}exp(-5(\frac{t-T}{80})^2),\quad t\le T\\    \lambda _{max},\quad t>T\\\end{array} \right.</script><h1 id="标题深度和目录深度"><a href="#标题深度和目录深度" class="headerlink" title="标题深度和目录深度"></a>标题深度和目录深度</h1><p>默认只到subsubsection。想要显示更深，在导言区加入：</p><div class="code-wrapper"><pre class="line-numbers language-latex" data-language="latex"><code class="language-latex"><span class="token function selector">\setcounter</span><span class="token punctuation">&#123;</span>tocdepth<span class="token punctuation">&#125;</span><span class="token punctuation">&#123;</span>3<span class="token punctuation">&#125;</span> # toc即table of content，表示目录显示的深度<span class="token function selector">\setcounter</span><span class="token punctuation">&#123;</span>secnumdepth<span class="token punctuation">&#125;</span><span class="token punctuation">&#123;</span>4<span class="token punctuation">&#125;</span> #secnum即section number，表示章节编号的深度<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><h1 id="vs-code-open-json"><a href="#vs-code-open-json" class="headerlink" title="vs code open json"></a>vs code open json</h1><p><a href="https://blog.csdn.net/qq_24502469/article/details/114269806">json配置</a></p>]]></content>
    
    
    <categories>
      
      <category>utils</category>
      
      <category>latex</category>
      
    </categories>
    
    
    <tags>
      
      <tag>utils</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>anaconda+pycharm+pytorch1.7+tensorflow1.14.0+tensorflow2.2.0多种环境共存</title>
    <link href="/2021/12/04/pythonenvs2/"/>
    <url>/2021/12/04/pythonenvs2/</url>
    
    <content type="html"><![CDATA[<h1 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h1><p>Anaconda+pycharm+pytorch 的安装见我<a href="https://blog.csdn.net/qq_41380292/article/details/107693355">前期博文(点这里)</a></p><h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><p>Anaconda起到一个包管理的作用，可以将不同环境的python、库等分隔开来，互不影响。所以我们可以搭建不同的框架和环境且互相独立。（为了保证我和师兄的代码互相能看懂，只能舍弃pytorch了。pytorch yyds！）</p><h1 id="查看匹配"><a href="#查看匹配" class="headerlink" title="查看匹配"></a>查看匹配</h1><p>首先明确一件事情，tensorflow、cudnn、cudatoolkit（cuda）是我们每个tensorflow环境需要安装的。这三个库之间是有一个匹配关系。这个匹配关系不对会导致安装后报错。建议大家先明确一下匹配关系，需要下载哪个版本的（百度或者官网查）。<br>下面给出我安装的两个版本的对应关系：<br>| tensorflow版本 | cudnn | cudatoolkit |<br>| ——————— | ——- | —————- |<br>| 1.14.0         | 7.6.4 | 10.0        |<br>| 2.2.0          | 7.6.5 | 10.1        |</p><h1 id="新建Anaconda环境"><a href="#新建Anaconda环境" class="headerlink" title="新建Anaconda环境"></a>新建Anaconda环境</h1><p>打开Anaconda或Anaconda prompt，然后按照前面博文中<a href="https://blog.csdn.net/qq_41380292/article/details/107693355">“创建新环境”</a>小节操作即可。<br>在此我创建了一个名为tensorflow1_14_0的新环境。python版本选择3.6<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20201205225552692.png" alt="在这里插入图片描述"></p><h1 id="安装CUDA"><a href="#安装CUDA" class="headerlink" title="安装CUDA"></a>安装CUDA</h1><p>首先打开Anaconda prompt，激活刚刚创建的环境：<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">activate tensorflow1_14_0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20201205230032718.png" alt="在这里插入图片描述"><br>可以看到环境从之前的mytorch（我修改了默认，正常默认环境是base）变为了新创建的tensorflow1_14_0<br>然后在Anaconda prompt中通过命令下载==对应版本的cuda==：<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">conda install cudatoolkit<span class="token operator">=</span><span class="token number">10.0</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>这里建议大家参考<a href="https://blog.csdn.net/qq_41380292/article/details/107693355">我的博文</a>换源，如果不换源会很慢。<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/2020120523150050.png" alt="在这里插入图片描述"></p><h1 id="安装cudnn"><a href="#安装cudnn" class="headerlink" title="安装cudnn"></a>安装cudnn</h1><p>同样在Anaconda prompt中键入(注意版本号)：<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">conda install cudnn<span class="token operator">=</span><span class="token number">7.6</span><span class="token number">.4</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/2020120523190131.png" alt="在这里插入图片描述"></p><h1 id="安装tensorflow"><a href="#安装tensorflow" class="headerlink" title="安装tensorflow"></a>安装tensorflow</h1><p>tensorflow分为CPU版本和GPU版本。GPU版本自带了CPU版本。<br>如果想安装CPU版本，使用命令:<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">pip install <span class="token operator">-</span>i https<span class="token punctuation">:</span><span class="token operator">//</span>pypi<span class="token punctuation">.</span>doubanio<span class="token punctuation">.</span>com<span class="token operator">/</span>simple<span class="token operator">/</span> tensorflow<span class="token operator">==</span><span class="token number">1.14</span><span class="token number">.0</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>这里借助了豆瓣源，实测要快一些。<br>如果安装GPU版本，如下：<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">pip install <span class="token operator">-</span>i https<span class="token punctuation">:</span><span class="token operator">//</span>pypi<span class="token punctuation">.</span>doubanio<span class="token punctuation">.</span>com<span class="token operator">/</span>simple<span class="token operator">/</span> tensorflow_gpu<span class="token operator">==</span><span class="token number">1.14</span><span class="token number">.0</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>然后在Anaconda中进入python编译：<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">python<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>调用tensorflow包<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> tensorflow<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>会出现一堆错误：<br>FutureWarning: Passing (type, 1) or ‘1type’ as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / ‘(1,)type’.<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20201205232816515.png" alt="在这里插入图片描述"><br>不要怕，问题很简单，numpy版本过高。这是我用Anaconda经常会遇到的问题。每次都是numpy整个最新版，不知道是为什么。<br>我们需要做的就是给numpy降级。如下我给了两个版本的参考（我是这么装的没问题），大家有兴趣可以试试其他版本。</p><div class="table-container"><table><thead><tr><th>tensorflow版本</th><th>numpy版本</th></tr></thead><tbody><tr><td>1.14.0</td><td>1.16.0</td></tr><tr><td>2.2.0</td><td>1.17.0</td></tr><tr><td>为了降级，输入命令（我这里是tensorflow1.14.0，对应的numpy1.16.0）：</td></tr></tbody></table></div><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">conda install numpy<span class="token operator">==</span><span class="token number">1.16</span><span class="token number">.0</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20201205233318517.png" alt="在这里插入图片描述"><br>然后可以检查一下是否安装完成了，即在python编译器中输入:<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf tf<span class="token punctuation">.</span>__version__<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20201205234611462.png" alt="在这里插入图片描述"><br>看到确实是1.14.0<br>==完成了吗？？==<br>试一下pycharm，同之前的博文，在pycharm中的编译器选择Existing environment-&gt;anaconda安装目录下的env-&gt;tensorflow1_14_0（环境名）-&gt;python.exe<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20201205234951589.png" alt="在这里插入图片描述"><br> 等待库全部加载完，新建一个python文件，键入以下代码测试：<br> <div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"> <span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf<span class="token keyword">import</span> os<span class="token comment"># 降低警告优先级，去掉一堆加速警告。可以不写</span>os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'TF_CPP_MIN_LOG_LEVEL'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'2'</span>gpu_device_name <span class="token operator">=</span> tf<span class="token punctuation">.</span>test<span class="token punctuation">.</span>gpu_device_name<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>gpu_device_name<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>test<span class="token punctuation">.</span>is_gpu_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 返回True或者False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20201205235651478.png" alt="在这里插入图片描述"><br>可以看到安装成功！！！：）<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20201206000927183.png" alt="在这里插入图片描述"><br>我现在四个环境共存了。</p><h1 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h1><ol><li>tensorflow2.2.0安装过程完全一样，只是把cudnn、tensorflow、cudatoolkit的版本号改掉就可。</li><li>可能会遇到DLL 未找到。。。之类的错误，可能是没装Microsoft vistal C++ 。但我的解决方案是在环境变量中把新建的环境下的路径添加到环境变量中，如：<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/20201206000036986.png" alt="在这里插入图片描述"><br>有兴趣可以试试。</li></ol><p>（tensorflow1.x真的不友好TAT还是keras和pytorch好使）</p>]]></content>
    
    
    <categories>
      
      <category>envs</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Deep Learning</tag>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>FixMatch文章解读+算法流程+核心代码详解</title>
    <link href="/2021/12/04/Fixmatch/"/>
    <url>/2021/12/04/Fixmatch/</url>
    
    <content type="html"><![CDATA[<h1 id="FixMatch"><a href="#FixMatch" class="headerlink" title="FixMatch"></a>FixMatch</h1><p><em>本博客仅做算法流程疏导，具体细节请参见原文</em></p><h2 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h2><p><a href="https://arxiv.org/abs/2001.07685">查看原文点这里</a></p><h2 id="Github代码"><a href="#Github代码" class="headerlink" title="Github代码"></a>Github代码</h2><p><a href="https://github.com/kekmodel/FixMatch-pytorch">Github代码点这里</a></p><h2 id="解读"><a href="#解读" class="headerlink" title="解读"></a>解读</h2><p> FixMatch算法抓住了半监督算法的两个重要观点，第一个是一致性正则化，第二个是伪标记。一致性正则化在<a href="https://blog.csdn.net/qq_41380292/article/details/119277938?spm=1001.2014.3001.5501">MixMatch</a>中已经介绍过了，在此不再赘述。伪标记是一种常用的半监督算法。</p><h3 id="伪标记"><a href="#伪标记" class="headerlink" title="伪标记"></a>伪标记</h3><p>伪标记（pseudo label）其实算最早的一类半监督算法，代表算法self-training。简单地说就是通过训练的模型对无标记样本打标签，这个标签有对有错，通过一些方法筛选标签后，选择一部分无标记样本和模型打的标签一起送入模型继续训练。伪标记的方法最大问题在于，如何保证伪标记的正确性。因为当模型打的标签提供了较多的错误信息时，会使模型的训练结果更劣。一般常见的筛选方式是将模型输出的预测结果($Softmax$之后)进行阈值判断，其$argmax$的概率大于阈值，才认为是有效标记，否则将此无标记样本丢弃。</p><h3 id="整体算法"><a href="#整体算法" class="headerlink" title="整体算法"></a>整体算法</h3><p>FixMatch算法并不复杂，结合一致性正则化和伪标记两种算法。由其论文中的流程图就可以很好的理解。</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/4f0c97744f73673206e011210b4495f8.png" alt="image-20210802101107656"></p><p>对于有标记样本，进行正常的监督学习，损失函数为$CrossEntropyLoss$，得到$L_s$。其公式表达如下：</p><p>$L<em>s=\frac{1}{B}\sum^B</em>{b=1}H(p_b,p_m(y|\alpha(x_b)))$</p><p>对于无标记样本，参照上图，共四步。</p><p><strong>第一步</strong>，先对无标记样本进行扩增(Augment)，扩增分为强扩增和弱扩增，弱扩增使用标准的旋转和移位；强扩增使用RandAugment和CTAugment两种算法。</p><p><strong>第二步</strong>，对扩增后的样本进行预测。对于弱扩增的样本，输出的预测结果($Softmax$之后的)最高预测概率(即$argmax$的结果)大于阈值(图中的虚线)，则认为是有效的样本，将其预测结果作为标签（这就是pseudo label）。</p><p><strong>第三步</strong>：对强扩增的样本，输出的预测结果和对应弱标记样本得到的标签做$CrossEntropyLoss$，得到损失函数$L_u$。其公式表达为：</p><p>$L<em>u=\frac{1}{\mu B}\sum^{\mu B}</em>{b=1}\mathcal{1}(max(q_b)\geq \tau )H(\hat{q_b},p_m(y|\mathcal{A}(u_b)))$</p><p>简而言之就是选择$max(q_b)\geq \tau$的$H(\hat{q_b},p_m(y|\mathcal{A}(u_b))$作为$L_u$的组成成分，参与反向梯度传播更新。</p><p><strong>第四步</strong>：最终损失函数为$Loss = L_s+\alpha L_u$，$\alpha$是超参数。</p><p>对$Loss$反向梯度传播完成整个算法模型更新。</p><h3 id="核心代码解读"><a href="#核心代码解读" class="headerlink" title="核心代码解读"></a>核心代码解读</h3><p>这里读取一个batch的操作，和前一篇<a href="https://blog.csdn.net/qq_41380292/article/details/119277938?spm=1001.2014.3001.5501">MixMatch</a>的代码实现相同，为了读取指定次数的batch，而不通过Dataloader。<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> batch_idx <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>eval_step<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        inputs_x<span class="token punctuation">,</span> targets_x <span class="token operator">=</span> labeled_iter<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">except</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> args<span class="token punctuation">.</span>world_size <span class="token operator">></span> <span class="token number">1</span><span class="token punctuation">:</span>            labeled_epoch <span class="token operator">+=</span> <span class="token number">1</span>            labeled_trainloader<span class="token punctuation">.</span>sampler<span class="token punctuation">.</span>set_epoch<span class="token punctuation">(</span>labeled_epoch<span class="token punctuation">)</span>        labeled_iter <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>labeled_trainloader<span class="token punctuation">)</span>        inputs_x<span class="token punctuation">,</span> targets_x <span class="token operator">=</span> labeled_iter<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        <span class="token punctuation">(</span>inputs_u_w<span class="token punctuation">,</span> inputs_u_s<span class="token punctuation">)</span><span class="token punctuation">,</span> _ <span class="token operator">=</span> unlabeled_iter<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">except</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> args<span class="token punctuation">.</span>world_size <span class="token operator">></span> <span class="token number">1</span><span class="token punctuation">:</span>            unlabeled_epoch <span class="token operator">+=</span> <span class="token number">1</span>            unlabeled_trainloader<span class="token punctuation">.</span>sampler<span class="token punctuation">.</span>set_epoch<span class="token punctuation">(</span>unlabeled_epoch<span class="token punctuation">)</span>        unlabeled_iter <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>unlabeled_trainloader<span class="token punctuation">)</span>        <span class="token punctuation">(</span>inputs_u_w<span class="token punctuation">,</span> inputs_u_s<span class="token punctuation">)</span><span class="token punctuation">,</span> _ <span class="token operator">=</span> unlabeled_iter<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><br>得到<strong>strong_augment</strong>样本和<strong>weak_augment</strong>样本，分别为<strong>logits_u_s</strong>和<strong>logits_u_w</strong>。<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">logits <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>logits <span class="token operator">=</span> de_interleave<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> <span class="token number">2</span><span class="token operator">*</span>args<span class="token punctuation">.</span>mu<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>logits_x <span class="token operator">=</span> logits<span class="token punctuation">[</span><span class="token punctuation">:</span>batch_size<span class="token punctuation">]</span>logits_u_w<span class="token punctuation">,</span> logits_u_s <span class="token operator">=</span> logits<span class="token punctuation">[</span>batch_size<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>chunk<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div><br>对有标记样本做$CrossEntropyLoss$<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">Lx <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>logits_x<span class="token punctuation">,</span> targets_x<span class="token punctuation">,</span> reduction<span class="token operator">=</span><span class="token string">'mean'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>通过<strong>weak_augment</strong>样本计算伪标记<strong>pseudo label</strong>和<strong>mask</strong>，其中，<strong>mask</strong>用来筛选哪些样本最大预测概率超过阈值，可以拿来使用，哪些不能使用<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">pseudo_label <span class="token operator">=</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>logits_u_w<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span>args<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>max_probs<span class="token punctuation">,</span> targets_u <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>pseudo_label<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>mask <span class="token operator">=</span> max_probs<span class="token punctuation">.</span>ge<span class="token punctuation">(</span>args<span class="token punctuation">.</span>threshold<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div><br>计算无标记样本的损失函数$L_u$，其中通过<strong>mask</strong>进行样本筛选<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">Lu <span class="token operator">=</span> <span class="token punctuation">(</span>F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>logits_u_s<span class="token punctuation">,</span> targets_u<span class="token punctuation">,</span> reduction<span class="token operator">=</span><span class="token string">'none'</span><span class="token punctuation">)</span> <span class="token operator">*</span> mask<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>完整损失函数如下<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">loss <span class="token operator">=</span> Lx <span class="token operator">+</span> args<span class="token punctuation">.</span>lambda_u <span class="token operator">*</span> Lu<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>反向梯度更新，完成！~</p>]]></content>
    
    
    <categories>
      
      <category>Paper Reading</category>
      
      <category>Semi-Supervised Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MixMatch文章解读+算法流程+核心代码详解</title>
    <link href="/2021/12/04/Mixmatch/"/>
    <url>/2021/12/04/Mixmatch/</url>
    
    <content type="html"><![CDATA[<h1 id="MixMatch"><a href="#MixMatch" class="headerlink" title="MixMatch"></a>MixMatch</h1><p><em>本博客仅做算法流程疏导，具体细节请参见原文</em></p><h2 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h2><p><a href="https://arxiv.org/abs/1905.02249">查看原文点这里</a></p><h2 id="Github代码"><a href="#Github代码" class="headerlink" title="Github代码"></a>Github代码</h2><p><a href="https://github.com/YU1ut/MixMatch-pytorch.git">Github代码点这里</a></p><h2 id="解读"><a href="#解读" class="headerlink" title="解读"></a>解读</h2><p>MixMatch抓住了半监督算法的两个重要观点：第一是<strong>熵最小化</strong>；第二是<strong>一致性正则化</strong>。结合这两个观点的算法就形成了MixMatch。</p><h3 id="熵最小化"><a href="#熵最小化" class="headerlink" title="熵最小化"></a>熵最小化</h3><p>半监督算法的一个常见假设就是分类的决策边界不应该通过数据分布的高密度区域。这句话简单的理解可以想象一个聚类模型，其决策边界一定是在簇与簇之间的稀疏边界上，不可能穿过一个簇的中心（高密度区域）。而实现这一点的一种方法就是要求分类器对未标记数据输出低熵预测。MixMatch中使用一个”sharpening”函数来隐式实现熵最小化。所谓熵最小化、低熵预测，都是指使输出概率分布比较有“偏向性”，而不希望输出一个“平均的预测”。熵在信息论中是不确定度的度量，根据离散模型的熵最大定理，可知在均匀分布时熵取得最大值，换句话说，出现一个确定的分布，即某一类的概率是1，其余类的概率是0时，熵为0。也就是说想要得到熵最小，就得使分类器输出后的模型预测概率集中分配给某一类。后面再介绍“sharpening”函数如何实现这一点。</p><h3 id="一致性正则化"><a href="#一致性正则化" class="headerlink" title="一致性正则化"></a>一致性正则化</h3><p>一致性正则化也是一个常见的半监督假设。<a href="https://blog.csdn.net/qq_41380292/article/details/119248049">VAT</a>、<a href="https://blog.csdn.net/qq_41380292/article/details/119218902">MeanTeacher</a>等其实都或多或少使用了这种假设。其核心在于，我们希望一个样本和其加扰版本（通常图像中称为Augment）通过分类器后，得到相似的输出。其实也就是说分类边界不应该穿过数据分布的高密度区域。如下图，红色点是原始样本，蓝色和绿色为其扰动版本，红色同心圆的虚线圆是我们期望的容差范围，即在这个区间类的都应该认为和其中心数据点为同一类。通过扰动数据点的加入，将决策边界推到合适的位置，使分类器的鲁棒性更强。</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/391a4b60403d99fb826ff03a3e1bf178.png" alt="Consistency Regularization"></p><p>一般而言，通过对原始样本和其扰动版本的分类器输出进行衡量，即可实现一致性正则化，常见的衡量方式有MSE、KL散度、JS散度等。在MixMatch中通过对图像的标准数据增强(水平翻转、裁剪)实现扰动(Augment)，采用MSE准则方式衡量。</p><p>总得来说，算法有以下步骤：</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/e89857b0f4f83f2c160402828d2b381d.png" alt="屏幕截图 2021-07-31 154634"></p><p>归结而言有五个步骤：</p><p><strong>第一步</strong>，对数据进行扩增(Augment)。扩增分为对有标记数据集$X$的扩增和对无标记数据集$U$的扩增，分别记为$\hat{X}$和$\hat{U}$。对$X$扩增一次，对$U$扩增$K$次，文章中取$K=2$。因为在取batch时，$Batch Size <em>U = BatchSize_X$，所以扩增后$Batch Size </em>{\hat{U}} = K\cdot BatchSize_{\hat{X}}$。</p><p><strong>第二步</strong>，计算平均预测分布。此步骤仅对数据集$\hat{U}$进行。即通过如下公式计算，其中$(\hat{u_{b,k}},y)$是$\hat{U}$的一个$Batch$：</p><script type="math/tex; mode=display">\bar{q_b}=\frac{1}{K}\sum_kP_{model}(y|\hat{u_{b,k}};\theta)</script><p>值得注意的是，$P<em>{model}(y|\hat{u</em>{b,k}};\theta)$是$Softmax$之后的预测概率分布。</p><p><strong>第三步</strong>，通过$sharpening$函数完成分布的锐化，其计算公式如下：</p><script type="math/tex; mode=display">Sharpen(p,T)_i=\frac{p_i^{\frac{1}{T}}}{\sum^L_{j=1}p_j^{\frac{1}{T}}}</script><p>当超参数$T\to 0$时，$Sharpen(p,T)$趋向于$one-hot$分布，即其中一个类别的概率为1，其余概率为0；锐化后的概率分布作为$\hat{U}$的数据标签(pseudo label)。</p><p><strong>第四步</strong>，通过$MixUp$完成新数据集的构建。先将第一步扩增后的$\hat{X}$和$\hat{U}$进行拼接再打乱顺序，得到$W=Shuffle(Concat(\hat{X},\hat{U}))$，然后再将$W$分为两部分，第一部分大小与$\hat{X}$相同(也与$X$相同)，记为$W_x$；第二部分大小与$\hat{U}$相同(也与$U$相同)，记为$W_u$。然后将$W_x$和$\hat{X}$进行$MixUp$，$W_u$和$\hat{U}$进行$MixUp$，得到$X’$和$U’$。$MixUp$步骤如下：</p><script type="math/tex; mode=display">\lambda\sim Beta(\alpha,\alpha)</script><script type="math/tex; mode=display">\lambda'=max(\lambda,1-\lambda)</script><script type="math/tex; mode=display">x'=\lambda'x_1+(1-\lambda')x_2</script><script type="math/tex; mode=display">p'=\lambda'p_1+(1-\lambda')p_2</script><p><strong>第五步</strong>，计算半监督损失函数，分为在标记数据集$X’$上的损失函数$L_x$和在无标记数据集$U’$上的损失函数$L_u$，公式如下：</p><script type="math/tex; mode=display">L_x=\frac{1}{|X'|}\sum_{x,p\in X'}H(p,P_{model}(y|x;\theta))</script><script type="math/tex; mode=display">L_u=\frac{1}{L|U'|}\sum_{u,q\in U'}||q-P_{model}(y|u;\theta)||^2_2</script><script type="math/tex; mode=display">L=L_x+\lambda_UL_u</script><p>其中$H(\cdot)$是$CorssEntropyLoss$；$L_u$其实就是$MSE$准则下的误差项。</p><p>反向梯度传播即可完成整个MixMatch算法</p><h2 id="核心代码详解"><a href="#核心代码详解" class="headerlink" title="核心代码详解"></a>核心代码详解</h2><p>图像的水平翻转、裁剪实现$Augment$：<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">transform_train <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    dataset<span class="token punctuation">.</span>RandomPadandCrop<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    dataset<span class="token punctuation">.</span>RandomFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    dataset<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span>transform_val <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    dataset<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><br>这里是在迭代过程中，手动取迭代器中的batch，而不是直接使用Dataloader。这种做法在最近的几篇文章代码复现中都遇见了，其主要目的是为了在一个epoch中可以迭代指定次数，而直接使用Dataloader只能迭代最多$ceil(\frac{样本总数}{BatchSize})$次，其中$ceil(\cdot)$是上取整函数，如果$drop_last$，则只能迭代$\frac{样本总数}{BatchSize}$次。代码中的两个try except是为了保证迭代器完全迭代一次后，重新加载迭代器，继续迭代，直到达到指定次数才跳转下一个epoch。<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> batch_idx <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>train_iteration<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">try</span><span class="token punctuation">:</span>         inputs_x<span class="token punctuation">,</span> targets_x <span class="token operator">=</span> labeled_train_iter<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token keyword">except</span><span class="token punctuation">:</span>         labeled_train_iter <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>labeled_trainloader<span class="token punctuation">)</span>         inputs_x<span class="token punctuation">,</span> targets_x <span class="token operator">=</span> labeled_train_iter<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token keyword">try</span><span class="token punctuation">:</span>         <span class="token punctuation">(</span>inputs_u<span class="token punctuation">,</span> inputs_u2<span class="token punctuation">)</span><span class="token punctuation">,</span> _ <span class="token operator">=</span> unlabeled_train_iter<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token keyword">except</span><span class="token punctuation">:</span>         unlabeled_train_iter <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>unlabeled_trainloader<span class="token punctuation">)</span>         <span class="token punctuation">(</span>inputs_u<span class="token punctuation">,</span> inputs_u2<span class="token punctuation">)</span><span class="token punctuation">,</span> _ <span class="token operator">=</span> unlabeled_train_iter<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><br>因为文章中取$K=2$，所以进行两次扩增，求输出概率的均值，其中<strong>output_u</strong>和<strong>output_u2</strong>分别为两次扩增后的模型输出结果：<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">outputs_u <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs_u<span class="token punctuation">)</span>outputs_u2 <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs_u2<span class="token punctuation">)</span>p <span class="token operator">=</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>outputs_u<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>outputs_u2<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>  <span class="token comment"># 求两次的平均值</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div><br>求Sharpening结果:<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">pt <span class="token operator">=</span> p<span class="token operator">**</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">/</span>args<span class="token punctuation">.</span>T<span class="token punctuation">)</span>targets_u <span class="token operator">=</span> pt <span class="token operator">/</span> pt<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>targets_u <span class="token operator">=</span> targets_u<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div><br>完成$MixUp$:<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">all_inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>inputs_x<span class="token punctuation">,</span> inputs_u<span class="token punctuation">,</span> inputs_u2<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>all_targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>targets_x<span class="token punctuation">,</span> targets_u<span class="token punctuation">,</span> targets_u<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>l <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>beta<span class="token punctuation">(</span>args<span class="token punctuation">.</span>alpha<span class="token punctuation">,</span> args<span class="token punctuation">.</span>alpha<span class="token punctuation">)</span>l <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>l<span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">-</span>l<span class="token punctuation">)</span>idx <span class="token operator">=</span> torch<span class="token punctuation">.</span>randperm<span class="token punctuation">(</span>all_inputs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>input_a<span class="token punctuation">,</span> input_b <span class="token operator">=</span> all_inputs<span class="token punctuation">,</span> all_inputs<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>target_a<span class="token punctuation">,</span> target_b <span class="token operator">=</span> all_targets<span class="token punctuation">,</span> all_targets<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>mixed_input <span class="token operator">=</span> l <span class="token operator">*</span> input_a <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> l<span class="token punctuation">)</span> <span class="token operator">*</span> input_bmixed_target <span class="token operator">=</span> l <span class="token operator">*</span> target_a <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> l<span class="token punctuation">)</span> <span class="token operator">*</span> target_b<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><br>然后计算损失函数:<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">logits <span class="token operator">=</span> <span class="token punctuation">[</span>model<span class="token punctuation">(</span>mixed_input<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token keyword">for</span> <span class="token builtin">input</span> <span class="token keyword">in</span> mixed_input<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    logits<span class="token punctuation">.</span>append<span class="token punctuation">(</span>model<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># put interleaved samples back</span>logits <span class="token operator">=</span> interleave<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span>logits_x <span class="token operator">=</span> logits<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>logits_u <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>logits<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>Lx<span class="token punctuation">,</span> Lu<span class="token punctuation">,</span> w <span class="token operator">=</span> criterion<span class="token punctuation">(</span>logits_x<span class="token punctuation">,</span> mixed_target<span class="token punctuation">[</span><span class="token punctuation">:</span>batch_size<span class="token punctuation">]</span><span class="token punctuation">,</span> logits_u<span class="token punctuation">,</span> mixed_target<span class="token punctuation">[</span>batch_size<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> epoch<span class="token operator">+</span>batch_idx<span class="token operator">/</span>args<span class="token punctuation">.</span>train_iteration<span class="token punctuation">)</span>loss <span class="token operator">=</span> Lx <span class="token operator">+</span> w <span class="token operator">*</span> Lu<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><br>反向梯度传播，结束。</p>]]></content>
    
    
    <categories>
      
      <category>Paper Reading</category>
      
      <category>Semi-Supervised Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Virtual Adversarial Training文章解读+算法流程+核心代码详解</title>
    <link href="/2021/12/04/VAT/"/>
    <url>/2021/12/04/VAT/</url>
    
    <content type="html"><![CDATA[<h1 id="Virtual-Adversarial-Training"><a href="#Virtual-Adversarial-Training" class="headerlink" title="Virtual Adversarial Training"></a>Virtual Adversarial Training</h1><p><em>本博客仅做算法流程疏导，具体细节请参见原文</em></p><h2 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h2><p><a href="http://arxiv.org/abs/1704.03976">查看原文请点这里</a></p><h2 id="Github代码"><a href="#Github代码" class="headerlink" title="Github代码"></a>Github代码</h2><p><a href="https://github.com/9310gaurav/virtual-adversarial-training">Github代码请点这里</a></p><h2 id="解读"><a href="#解读" class="headerlink" title="解读"></a>解读</h2><h3 id="对比Adversarial-Training和VAT"><a href="#对比Adversarial-Training和VAT" class="headerlink" title="对比Adversarial Training和VAT"></a>对比Adversarial Training和VAT</h3><p>VAT(Virtual Adversarial Training)和adversarial training类似。对原始训练样本添加一个比较小的扰动，会大概率使分类器分类出现错误，而我们一般希望分类器将原始样本和添加一个较小扰动的样本（加噪版本）分为同一类别，所以将扰动版本的数据也作为训练样本添加进训练，这样就增加了分类器的泛化能力。</p><p>传统的adversarial training 的扰动方向一般通过损失函数确定，即取损失函数上升的方向添加一个扰动。无标记样本没有标签，就无法算损失函数，故传统方法不适用，所以一般的adversarial training仅在监督学习中使用较多，而virtual adversarial training的创新在于能在无标记样本上实现扰动的计算，因为没用使用标签进行运算，而是用模型预测的结果替代标签，类似于persudo label，这就是virtual的含义</p><h4 id="Adversarial-Training"><a href="#Adversarial-Training" class="headerlink" title="Adversarial Training"></a>Adversarial Training</h4><p>adversarial training的数学表达如下，其中样本及标记$(x,y)$，当前epoch模型的参数$\theta$:<br><strong>损失函数</strong>：$J(\theta)=\frac{1}{N}\sum^{N}<em>{i=1}L(x,\theta)$<br>其中，<strong>单项损失</strong>计算表达式为：$L(x,\theta)=D(y,p(y|x+r,\theta))$<br><strong>扰动方向</strong>：$r=argmax</em>{|r|&lt;\xi}D(y,p(y|x+r,\theta))$</p><p>简单叙述为：找到一个扰动$r$，且$r$的大小受限，即$|r|&lt;\xi$，使其损失函数$L(x,\theta)=D(y,p(y|x+r,\theta))$取最大值，即在此$r$下上升最多。</p><h4 id="VAT"><a href="#VAT" class="headerlink" title="VAT"></a>VAT</h4><p>同样形式的，virtual adversarial training 的数学表达式如下，其中其中样本及标记$(x,y)$，当前epoch模型的参数$\theta$，前一个epoch的模型参数为$\hat{\theta}$：<br><strong>损失函数</strong>同上形式：$J(\theta)=\frac{1}{N}\sum^N<em>{i=1}L(x,\theta)$<br><strong>单项损失</strong>表达式==不同==(LDS称为局部平滑度)：$L(x,\theta)=D(p(y|x,\hat\theta),p(y|x+r,\theta))=LDS(x,\theta)$<br><strong>扰动方向</strong>：$r=argmax</em>{|r|&lt;\xi}D(p(y|x,\theta),p(y|x+r,\theta))$</p><p>简单叙述为：找到一个扰动$r$，且$r$的大小受限，即$|r|&lt;\xi$，使其损失函数$LDS(x,\theta)$取的最大值，即在此$r$下上升最多。</p><h2 id="代码详解"><a href="#代码详解" class="headerlink" title="代码详解"></a>代码详解</h2><p>代码核心就一个<strong>VAT_Loss</strong>的计算。整个框架的<strong>Loss=Classfier_Loss + VAT_Loss</strong>。其中<strong>Classfier_Loss</strong>损失函数为一般的监督网络的损失函数。<strong>VAT_Loss</strong>计算如下：<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">vat_loss</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> ul_x<span class="token punctuation">,</span> ul_y<span class="token punctuation">,</span> xi<span class="token operator">=</span><span class="token number">1e-6</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">2.5</span><span class="token punctuation">,</span> num_iters<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># find r_adv</span>    d <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>ul_x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>normal_<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_iters<span class="token punctuation">)</span><span class="token punctuation">:</span>        d <span class="token operator">=</span> xi <span class="token operator">*</span>_l2_normalize<span class="token punctuation">(</span>d<span class="token punctuation">)</span>        d <span class="token operator">=</span> Variable<span class="token punctuation">(</span>d<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        y_hat <span class="token operator">=</span> model<span class="token punctuation">(</span>ul_x <span class="token operator">+</span> d<span class="token punctuation">)</span>        delta_kl <span class="token operator">=</span> kl_div_with_logit<span class="token punctuation">(</span>ul_y<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y_hat<span class="token punctuation">)</span>        delta_kl<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        d <span class="token operator">=</span> d<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>        model<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    d <span class="token operator">=</span> _l2_normalize<span class="token punctuation">(</span>d<span class="token punctuation">)</span>    d <span class="token operator">=</span> Variable<span class="token punctuation">(</span>d<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    r_adv <span class="token operator">=</span> eps <span class="token operator">*</span> d    <span class="token comment"># compute lds</span>    y_hat <span class="token operator">=</span> model<span class="token punctuation">(</span>ul_x <span class="token operator">+</span> r_adv<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    delta_kl <span class="token operator">=</span> kl_div_with_logit<span class="token punctuation">(</span>ul_y<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y_hat<span class="token punctuation">)</span>    <span class="token keyword">return</span> delta_kl<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><br>其中对<strong>r_adv</strong>的计算采用的是一种快速计算方法。具体理论请<a href="http://arxiv.org/abs/1704.03976">查阅原文</a><br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">v_loss <span class="token operator">=</span> vat_loss<span class="token punctuation">(</span>model<span class="token punctuation">,</span> inputs_All<span class="token punctuation">,</span> logits_All<span class="token punctuation">,</span> eps<span class="token operator">=</span>args<span class="token punctuation">.</span>epsilon<span class="token punctuation">)</span>loss <span class="token operator">=</span> v_loss<span class="token operator">+</span>ce_lossoptimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><br>完整损失函数<strong>Loss=Classfier_Loss + VAT_Loss</strong>反向梯度传播更新网络即可。</p>]]></content>
    
    
    <categories>
      
      <category>Paper Reading</category>
      
      <category>Semi-Supervised Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MeanTeacher文章解读+算法流程+核心代码详解</title>
    <link href="/2021/12/04/meanteacher/"/>
    <url>/2021/12/04/meanteacher/</url>
    
    <content type="html"><![CDATA[<h1 id="MeanTeacher"><a href="#MeanTeacher" class="headerlink" title="MeanTeacher"></a>MeanTeacher</h1><p><em>本博客仅做算法流程疏导，具体细节请参见原文</em></p><h2 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h2><p><a href="https://arxiv.org/abs/1703.01780">原文链接点这里</a></p><h2 id="Github-代码"><a href="#Github-代码" class="headerlink" title="Github 代码"></a>Github 代码</h2><p><a href="https://github.com/iSarmad/MeanTeacher-SNTG-HybridNet">Github代码点这里</a></p><h2 id="解读"><a href="#解读" class="headerlink" title="解读"></a>解读</h2><p><a href="https://blog.csdn.net/hjimce/article/details/80551721">论文解读点这里</a></p><h2 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h2><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/975ace19f51b4497a580900f56bdd3a8.png" alt="MeanTeacher算法流程图"></p><h2 id="代码详解"><a href="#代码详解" class="headerlink" title="代码详解"></a>代码详解</h2><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">train_transform <span class="token operator">=</span> data<span class="token punctuation">.</span>TransformTwice<span class="token punctuation">(</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>       data<span class="token punctuation">.</span>RandomTranslateWithReflect<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>       transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>       transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>       transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.4914</span><span class="token punctuation">,</span> <span class="token number">0.4822</span><span class="token punctuation">,</span> <span class="token number">0.4465</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.2470</span><span class="token punctuation">,</span>  <span class="token number">0.2435</span><span class="token punctuation">,</span>  <span class="token number">0.2616</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   eval_transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>       transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>       transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.4914</span><span class="token punctuation">,</span> <span class="token number">0.4822</span><span class="token punctuation">,</span> <span class="token number">0.4465</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.2470</span><span class="token punctuation">,</span>  <span class="token number">0.2435</span><span class="token punctuation">,</span>  <span class="token number">0.2616</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>这是图像的预处理，TransformTwice可以读两个数据流。<br>在训练阶段，有：<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> ema_input<span class="token punctuation">)</span><span class="token punctuation">,</span> target<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>可以看到，通过train_transform出来的batch中，有两个数据流input和ema_input，其数据为同组数据加不同噪声后的形式，即算法流程中的$[X^{‘}_u,X^{‘}_s]$和$[X^{‘’}_u,X^{‘’}_s]$。每个数据流中包含了一定数量的有标记样本和无标记样本。target是这两个数据流的标签，其中无标记样本的标签为-1.<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">class_loss <span class="token operator">=</span> class_criterion<span class="token punctuation">(</span>model_out<span class="token punctuation">,</span> target_var<span class="token punctuation">)</span> <span class="token operator">/</span> minibatch_size<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">consistency_weight <span class="token operator">=</span> get_current_consistency_weight<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>consistency_loss <span class="token operator">=</span> consistency_weight <span class="token operator">*</span> consistency_criterion<span class="token punctuation">(</span>model_out<span class="token punctuation">,</span> ema_logit<span class="token punctuation">)</span> <span class="token operator">/</span> minibatch_size<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><br><strong>class_loss</strong>正如算法流程中的$Loss_1$，是stu模型输出结果和标签的CrossEntropyLoss；<strong>consistency_loss</strong>如算法流程中的$Loss_2$，是两个$[X^{‘}_u,X^{‘}_s]$和$[X^{‘’}_u,X^{‘’}_s]$的一致性损失，文章中直接选择的MSE损失函数。为了让模型训练更合理，$Loss_2$有一个渐增系数<strong>consistency_weight</strong>。<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># student 模型的更新</span>optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>global_step <span class="token operator">+=</span> <span class="token number">1</span>update_ema_variables<span class="token punctuation">(</span>model<span class="token punctuation">,</span> ema_model<span class="token punctuation">,</span> args<span class="token punctuation">.</span>ema_decay<span class="token punctuation">,</span> global_step<span class="token punctuation">)</span>  <span class="token comment"># teacher 模型的更新</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div><br><strong>student</strong>模型更新为$Loss=Loss_1+Loss_2$的反向梯度传播更新权值；<strong>teacher</strong>模型更新为当前<strong>student</strong>和上一个epoch的<strong>teacher</strong>模型的加权，即EMA平滑版本。</p><h2 id="主要思想"><a href="#主要思想" class="headerlink" title="主要思想"></a>主要思想</h2><p>算法比较简单，主要思想我觉得可以分为两部分：第一部分是原始样本的轻微扰动版本的预测结果应该与原样本属于同一类别；第二部分，希望通过模型的EMA版本作为分类更有可靠性的模型，即<strong>teacher</strong>来引导当前模型<strong>student</strong>模型训练，二者合并就是<strong>consistency_loss</strong>。</p>]]></content>
    
    
    <categories>
      
      <category>Paper Reading</category>
      
      <category>Semi-Supervised Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Mutual Information Neural Estimation梳理</title>
    <link href="/2021/12/04/MINEstimation/"/>
    <url>/2021/12/04/MINEstimation/</url>
    
    <content type="html"><![CDATA[<h1 id="Mutual-Information-Neural-Estimation"><a href="#Mutual-Information-Neural-Estimation" class="headerlink" title="Mutual Information Neural Estimation"></a>Mutual Information Neural Estimation</h1><p><a href="https://arxiv.org/abs/1801.04062">原文</a><br>参考：<a href="https://ruihongqiu.github.io/posts/2020/07/mine/">https://ruihongqiu.github.io/posts/2020/07/mine/</a></p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>互信息可以衡量两个随机变量之间的相关性：</p><script type="math/tex; mode=display">I(X;Z)=H(X)-H(X|Z)=H(Z)-H(Z|X)=H(X)+H(Z)-H(X,Z)</script><p>互信息量和KL散度的关系如下：</p><script type="math/tex; mode=display">I(X;Z)=\sum_{x\in \mathcal{X}}\sum_{z\in \mathcal{Z}}p(x,z)log\frac{p(x,y)}{p(x)p(y)}=D(p(x,y)||p(x)p(y))</script><p>但实际计算中，特别是对于高维空间来说，其边缘熵$H(X)$、$H(Z)$和条件熵$H(X|Z)$难以计算。<img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/6caf0ece6feba752f03bdf353c8859f5.png" alt="f89025089ec5c780a5d7a6df7c0193e"></p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>作者给出了两种利用梯度下降算法逼近的互信息估计，分别是<strong>The Donsker-Varadhan representation</strong>和<strong>The f-divergence representation</strong>。</p><h3 id="The-Donsker-Varadhan-representation"><a href="#The-Donsker-Varadhan-representation" class="headerlink" title="The Donsker-Varadhan representation"></a>The Donsker-Varadhan representation</h3><script type="math/tex; mode=display">D_{KL}(\mathbb{P}||\mathbb{Q})=\sup\limits_{T:\Omega \rightarrow \mathbb{R}}\mathbb{E_{\mathbb{P}}}[T]-log(\mathbb{E_{\mathbb{Q}}}[e^T])</script><p>其中$\mathbb{P}$和$\mathbb{Q}$是两个任意分布，$T$是从样本空间$\Omega$映射到实数$\mathbb{R}$的任意函数。</p><p>证明见大佬<a href="https://ruihongqiu.github.io/posts/2020/07/mine/">Ruihong Qiu</a>中2.2节</p><h3 id="The-f-divergence-representation"><a href="#The-f-divergence-representation" class="headerlink" title="The f-divergence representation"></a>The f-divergence representation</h3><p>The f-divergence representation可以看做是The Donsker-Varadhan representation的弱化版本，由2.1和不等式$\frac{x}{e}&gt; log\mathcal{x}$易得。</p><h3 id="最终形式"><a href="#最终形式" class="headerlink" title="最终形式"></a>最终形式</h3><script type="math/tex; mode=display">I(X;Z)\geq I_{\Theta}(X,Z)=\sup\limits_{\theta\in\Theta}\mathbb{E}_{\mathbb{P}_{XZ}}[T_{\theta}]-log(\mathbb{E}_{\mathbb{P}_X\mathbb{P}_Z}[e^{T_{\mathbb{\theta}}}])</script><p>我们希望用一个可以利用梯度更新的神经网络模型来计算上式，则有：</p><script type="math/tex; mode=display">\hat{I(X;Z)_n}=\sup\limits_{\theta\in\Theta}\mathbb{E}_{\mathbb{P}^{(n)}_{XZ}}[T_{\theta}]-log(\mathbb{E}_{\mathbb{P}^{(n)}_X\mathbb{\hat{P}}^{(n)}_Z}[e^{T_{\mathbb{\theta}}}])</script><p>其中$T$是一个神经网络；$X$、$Z$是两个样本集。得到估计的梯度为：</p><script type="math/tex; mode=display">\hat{G}_B=\mathbb{E}_B[\nabla_{\theta}T_{\theta}]-\frac{\mathbb{E}_B[\nabla_{\theta}T_{\theta}e^{T_{\theta}}]}{\mathbb{E}_B[e^{T_{\theta}}]}</script><p>但是这种方式是有偏的。可以通过滑动平均来估计$\mathbb{E}<em>B[e^{T</em>\theta}]$</p><p>完整的过程如下：</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/2478fae70b9b63793c0df71f8beabd17.png" alt="image-20210906185214958"></p>]]></content>
    
    
    <categories>
      
      <category>Paper Reading</category>
      
      <category>Self-Supervised Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Ubuntu+Anaconda+Pycharm从零开始完全配置</title>
    <link href="/2021/12/04/pythonenvs1/"/>
    <url>/2021/12/04/pythonenvs1/</url>
    
    <content type="html"><![CDATA[<h1 id="Ubuntu-Anaconda-Pycharm"><a href="#Ubuntu-Anaconda-Pycharm" class="headerlink" title="Ubuntu+Anaconda+Pycharm"></a>Ubuntu+Anaconda+Pycharm</h1><h2 id="安装VMware"><a href="#安装VMware" class="headerlink" title="安装VMware"></a>安装VMware</h2><p><a href="https://pan.baidu.com/s/1Kkmc94VEe7eNREiRvFHYkQ">分享我的版本VMware15.5</a></p><p>提取码：3cxe</p><p>一路傻瓜式安装</p><h2 id="下载Ubuntu"><a href="#下载Ubuntu" class="headerlink" title="下载Ubuntu"></a>下载Ubuntu</h2><p>去阿里的镜像源下载更快，<a href="http://mirrors.aliyun.com/ubuntu-releases/">点击这里</a>，我使用的是18.04.5</p><p>下载的时候注意选择64位或者32位（在18.04.5中都是64位的）。并且牢记，这对后面安装java jdk有影响。</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/7ad7fd0e3ef8d2f6d687bcfd8df788d1.png" alt="image-20210911141018838"></p><h2 id="安装Ubuntu"><a href="#安装Ubuntu" class="headerlink" title="安装Ubuntu"></a>安装Ubuntu</h2><p>打开VMware，选择主页—&gt;创建新的虚拟机</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/0b82637d87adf497934bb258f7d7f5b4.png" alt="image-20210911141238134"></p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/1631340809(1).jpg" alt="1631340809(1)" style="zoom:50%;" width="60%" /></p><p>选择自定义，下一步</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/image-20210911141449372.png" alt="image-20210911141449372" style="zoom: 50%;" width="60%"  /></p><p>默认设置，下一步</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/1631340961(1).jpg" alt="1631340961(1)" style="zoom:10%;" width="60%" /></p><p>选择稍后安装操作系统</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/a0e14eb9a1f248a084b999dc510f88e9.jpg" alt="请添加图片描述"></p><p>选择好客户机操作系统和版本</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/04bd7cc833554833be86dc74cecf44e5.jpg" alt="请添加图片描述"></p><p>选择名字和位置</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/05003a641be50ccdc7b57c0018d6ed8d.png" alt="image-20210911141939579"></p><p>处理器配置，这个需要根据个人的业务需求和电脑配置分配</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/a193d60e4440b59adbd97316c9c9df40.png" alt="image-20210911142028889"></p><p>虚拟机内存，分配大小也需要根据业务需求和电脑配置决定，太小了虚拟机会比较卡</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/d9590b8b0ea60d2c10685bc4f56959f1.png" alt="image-20210911142109837"></p><p>网络类型，默认</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/ee7859717696af99d153d4bd091d212c.png" alt="image-20210911142134408"></p><p>IO默认</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/1e4e1225d0a6a518438abc52edaf52eb.png" alt="image-20210911142153119"></p><p>磁盘默认</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/dbd935507bf7bb03ca2145105b2fa06c.png" alt="image-20210911142213674"><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/fdf81c9f3b4c4e5aa63e37f5c069385c.jpg" alt="请添加图片描述"></p><p>创建新虚拟磁盘</p><p>磁盘大小看个人需求</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/3e035a41326e42a867ced8d63acdb9d3.png" alt="image-20210911142405386"></p><p>磁盘文件的存储地址，默认即可</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/72341f4e6e3a4d2fa07aee8d3371cf62.png" alt="在这里插入图片描述"></p><p>选择自定义硬件，在新CD/DVD中选择使用ISO映像文件，选择之前下载的Ubuntu操作系统，然后点右下角关闭，点击完成。</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/41762965302b4f21945f9227aaa65584.jpg" alt="请添加图片描述"></p><h2 id="安装系统"><a href="#安装系统" class="headerlink" title="安装系统"></a>安装系统</h2><p><strong>安装系统时容易出现安装界面显示不完全，导致continue按钮无法选中，可以按住alt键拖动窗口即可。</strong></p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/060accad7e28f04cd82ef62f7dffa127.png" alt="image-20210911142826563"></p><p>选择虚拟机，点击开启此虚拟机</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/7b1ddc722f134c2dab8411f8ad395ad5.png" alt=""></p><p>建议直接装英文版，中文字符使用不方便。点击Install Ubuntu</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/d6ec3004af3b4496d6181e4c6e224d5a.png" alt="image-20210911143054598"></p><p>选择键盘，就选英文键盘或者中文键盘都可以。</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/8bf9155f4fc323d6d2522d8919c2b9bd.png" alt="image-20210911143209246"></p><p>默认安装一些软件</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/8aeb4c04bedbab3ff66aa2859f4fe64d.png" alt="image-20210911143349971"></p><p>选择默认的安装方式，会将磁盘文件中的数据给清楚（磁盘文件指的是安装Ubuntu的那个50G磁盘文件）</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/78c41df3879144a298aab3be46163583.png" alt=""></p><p>continue开始安装，选择城市</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/4299c74e0a568ad2330f3b39e1de792f.png" alt="image-20210911143642255"></p><p>设置账号密码</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/9efd1b042ff6eefc19e7a6605bdb09a0.png" alt="image-20210911143701815"></p><p>安装完成后要求重启，完成安装。</p><h2 id="Ubuntu-全屏，VMware-tools安装"><a href="#Ubuntu-全屏，VMware-tools安装" class="headerlink" title="Ubuntu 全屏，VMware tools安装"></a>Ubuntu 全屏，VMware tools安装</h2><p>安装完之后是非全屏的，需要安装VMware tools才能全屏显示</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/105ec533b9e24e5c9abeb54fd4962ab3.png" alt="在这里插入图片描述"></p><p>查看VMware tools的位置</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/48756f63548d3435d9f3444cf6481d95.png" alt="image-20210911145415327"></p><p>用Terminal（ctrl+alt+t打开）新建一个文件夹以供VMware tools 解压，建在哪都可以</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">cd Desktopmkdir tools<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><p>然后右键VMware tools 压缩包，解压到新建的文件夹中</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/0f51ede49666ebe160f76dffdb621352.png" alt="image-20210911145859028"></p><p>如果显示Not Enough free Space…就先将压缩文件移到tools文件夹中再直接解压。</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/bd15a253c2837d5bbb8e66d46c4d3c2c.png" alt="image-20210911150013994"></p><p>然后进入解压后的文件夹，在此页面打开Terminal，进入超级用户</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">sudo su<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>然后输入密码，登录超级用户</p><p>然后运行安装程序：</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">.&#x2F;vmware-install.pl<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>输入yes开始安装，一路回车</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/cb67c6c1b897ccf02b066d5ac4dba2a7.png" alt="image-20210911150651319"></p><p>看到Enjoy—the Vmware team就安装完成了，全屏的时候就已经可以自动调整大小了。</p><h2 id="安装java-jdk"><a href="#安装java-jdk" class="headerlink" title="安装java jdk"></a>安装java jdk</h2><p>jdk包括了jre和jvm，分别是Java运行环境和Java虚拟机安装pycharm需要用得到，装pycharm和Anaconda之前先安装这个。</p><p>先在Oracle官网下载对应的jdk，个人觉得jdk8已经够用了，新的无非是多一些新特性，暂时用不上。</p><p><a href="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-P3hK6zd6-1631348653338">下载地址点这里</a>(C:\Users\joffrey\AppData\Roaming\Typora\typora-user-images\image-20210911151030631.png)][外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-w2Jxy34Q-1631348653339)(C:\Users\joffrey\AppData\Roaming\Typora\typora-user-images\image-20210911151030631.png)])</p><p>注意下载jdk，jdk里面带有jre，不要下错了。另外要注意是64位还是32位，下错了会出现以下错误：<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/6adfa37ec30141a85239af03bd35cf7d.png" alt="image-20210910154704281"></p><p>还是用jdk8</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/73d98e58baaddd482d8e692f1892fe58.png" alt="image-20210911151144787"></p><p>先新建一个文件夹，存储解压后的文件</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">cd Desktopmkdir jdk<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><p>然后解压文件到Desktop/jdk文件夹</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">sudo tar zxvf ~&#x2F;Downloads&#x2F;jdk-8u301-linux-x64.tar.gz -C ~&#x2F;Desktop&#x2F;jdk<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/3b780ae7f968f8a5cc8660fe7f2e0ccd.png" alt="image-20210911151920137"></p><p>添加环境变量：</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">sudo gedit ~&#x2F;.bashrc<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>并在打开的文件中输入，第一行路径需要根据个人的解压路径填写</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">export JAVA_HOME&#x3D;&#x2F;home&#x2F;lc&#x2F;Desktop&#x2F;jdk&#x2F;jdk1.8.0_301export JRE_HOME&#x3D;$&#123;JAVA_HOME&#125;&#x2F;jre export CLASSPATH&#x3D;:$&#123;JAVA_HOME&#125;&#x2F;lib:$&#123;JRE_HOME&#125;&#x2F;lib export PATH&#x3D;$&#123;JAVA_HOME&#125;&#x2F;bin:$PATH<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div><p>然后使环境变量生效:</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">source ~&#x2F;.bashrc<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>最后查看是否完成</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">java -version<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/a000c5813faf481be8027494ffee14bc.png" alt="image-20210911152700050"></p><p>有版本信息就说明完成了。</p><h2 id="安装pycharm"><a href="#安装pycharm" class="headerlink" title="安装pycharm"></a>安装pycharm</h2><p><a href="https://www.jetbrains.com/pycharm/download/#section=linux">官网下载</a></p><p>解压下载的文件夹到目录，我这里是解压到Pycharm文件夹下：</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">mkdir ~&#x2F;Pycharmsudo tar zxvf ~&#x2F;Downloads&#x2F;pycharm-professional-2021.2.1.tar.gz -C ~&#x2F;Pycharm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><p>进入文件夹/home/lc/Pycharm/pycharm-2021.2.1/bin 运行pycharm.sh</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">cd &#x2F;home&#x2F;lc&#x2F;Pycharm&#x2F;pycharm-2021.2.1&#x2F;binsh pycharm.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/f9b266960a55dbd98b88d5f04fa38b36.png" alt="image-20210911153916643"></p><p>选择continue</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/e8564be8122306f39d1220160b33fce9.png" alt="image-20210911153947829"></p><p>初次安装，不导入设置。剩下的就是激活了。网上有很多激活教程，或者免费试用30天，或者学生认证都可以。</p><h3 id="配置快捷按钮"><a href="#配置快捷按钮" class="headerlink" title="配置快捷按钮"></a>配置快捷按钮</h3><p>在/usr/share/applications 创建一个名为pycharm.desktop的文件</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">cd &#x2F;usr&#x2F;share&#x2F;applicationssudo gedit pycharm.desktop<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><p>在打开的文件中粘贴</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">[Desktop Entry]Version&#x3D;1.0Type&#x3D;ApplicationName&#x3D;PycharmIcon&#x3D;&#x2F;home&#x2F;lc&#x2F;Pycharm&#x2F;pycharm-2021.2.1&#x2F;bin&#x2F;pycharm.pngExec&#x3D;sh &#x2F;home&#x2F;lc&#x2F;Pycharm&#x2F;pycharm-2021.2.1&#x2F;bin&#x2F;pycharm.shMimeType&#x3D;application&#x2F;x-py;Name[en_US]&#x3D;pycharm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>主要注意 Icon是图标，Exec 执行的命令，其中的路径要改。</p><p>保存后就可以在所有的程序中看到pycharm了</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/44c46c71f28466a08a05445515f58ddd.png" alt="image-20210911154907027"></p><h2 id="Anaconda-安装"><a href="#Anaconda-安装" class="headerlink" title="Anaconda 安装"></a>Anaconda 安装</h2><p><a href="https://www.anaconda.com/products/individual#Downloads">官网下载</a></p><p>下载好了执行shell脚本</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">bash Anaconda3-2021.05-Linux-x86_64.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/1d05a7e0fd993b8f48185336b560f047.png" alt="image-20210911155401162"></p><p>然后一直回车，直到左下角没有—More—</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/7b4686cc3e10a564a2e4afaf2ae19ca1.png" alt="image-20210911155458129"></p><p>输入yes，回车</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/4622d61c5398e2a0a117908584bdc118.png" alt="image-20210911155529304"></p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/24f17f4634fe18a9406ea0ac6c2d18e6.png" alt="image-20210911155646959"></p><p>添加环境变量，路径根据自己的修改</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">echo &#39;export PATH&#x3D;&quot;&#x2F;home&#x2F;lc&#x2F;anaconda3&#x2F;bin&#x2F;:$PATH&quot;&#39; &gt;&gt; ~&#x2F;.bashrcsource ~&#x2F;.bashrc<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><p>完成后有两个步骤，第一换源，第二做启动图标，第三创建新环境和激活</p><h3 id="换源"><a href="#换源" class="headerlink" title="换源"></a>换源</h3><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">conda config --add channels https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud&#x2F;conda-forge&#x2F;conda config --add channels https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;free&#x2F;conda config --add channels https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;main&#x2F;conda config --append channels https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud&#x2F;fastai&#x2F;conda config --append channels https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud&#x2F;pytorch&#x2F;conda config --append channels https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud&#x2F;bioconda&#x2F;conda config --set show_channel_urls yes<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="启动图标"><a href="#启动图标" class="headerlink" title="启动图标"></a>启动图标</h3><p>类似于pycharm</p><p>创建一个文件：</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">cd &#x2F;usr&#x2F;share&#x2F;applications&#x2F;sudo gedit anaconda.desktop<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><p>然后在打开的文件中粘贴如下，注意修改Icon和Exec路径：</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">[Desktop Entry]Version&#x3D;1.0Name&#x3D;AnacondaType&#x3D;ApplicationGenericName&#x3D;AnacondaComment&#x3D;Scientific Python Development Environment - Python3Exec&#x3D;&#x2F;home&#x2F;lc&#x2F;anaconda3&#x2F;bin&#x2F;anaconda-navigatorCategories&#x3D;Development;Science;IDE;Qt;Education;Icon&#x3D;&#x2F;home&#x2F;lc&#x2F;anaconda3&#x2F;lib&#x2F;python3.8&#x2F;site-packages&#x2F;anaconda_navigator&#x2F;static&#x2F;images&#x2F;anaconda-icon-256x256.pngTerminal&#x3D;falseStartupNotify&#x3D;trueMimeType&#x3D;text&#x2F;x-python;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/df1750433d50f7a00c23b0547be0fbf6.png" alt="image-20210911161538078"></p><h3 id="创建新环境并激活"><a href="#创建新环境并激活" class="headerlink" title="创建新环境并激活"></a>创建新环境并激活</h3><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">conda create --name xxx python&#x3D;3.8<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>创建一个名字叫做xxx 的python版本为3.8的环境。我创造的环境名叫mytorch</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/ac71dda9b9df98464922c6def590ac46.png" alt="image-20210911161839275"></p><p>通过如下命令来激活环境</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">conda activate mytorch<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/394851edbfa2fef606abc4b98908cb28.png" alt="image-20210911161908586"></p><h2 id="Anaconda和Pycharm联合使用"><a href="#Anaconda和Pycharm联合使用" class="headerlink" title="Anaconda和Pycharm联合使用"></a>Anaconda和Pycharm联合使用</h2><p>参考之前的windows系统中的做法。即将pycharm中的编译器选择位anaconda环境的python编译器</p>]]></content>
    
    
    <categories>
      
      <category>envs</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>envs</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Representation Learning with Contrastive Predictive Coding梳理</title>
    <link href="/2021/12/04/cpc/"/>
    <url>/2021/12/04/cpc/</url>
    
    <content type="html"><![CDATA[<p>一种通用的无监督学习方法——对比预测编码。通过自回归模型预测潜在空间（高维空间）的未来，以学习高级表征。在训练阶段不涉及具体下游任务。</p><p><a href="https://arxiv.org/pdf/1807.03748.pdf">原文</a><br>参考：<a href="https://zhuanlan.zhihu.com/p/129076690">https://zhuanlan.zhihu.com/p/129076690</a></p><h2 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h2><ol><li>将高维数据压缩到更加紧密的潜在嵌入空间，这个空间中条件预测更容易建模。</li><li>在这个潜在空间中使用强大的<strong>自回归</strong>模型来做多步未来预测。</li><li>损失函数依靠噪声对比估计，这是与自然语言模型中用于学习词嵌入类似的方式，需要整个模型以端到端的形式进行训练。将最终的模型（对比预测编码，CPC）用在了很多不同的数据模态中，包括图像、语音、自然语言和强化学习，结果表明同样的机制在每一个领域中都学到了有趣的高级表征，而且优于其他方法。</li></ol><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/be8d1c3abdacb2f159997d74695c8d11.png" alt="image-20210908124633513"></p><p>对于输入样本$x<em>t$，有一个非线性编码器$g</em>{enc}$将其映射为潜在表示序列$z<em>t=g</em>{enc}(x<em>t)$；对于$t$时刻之前的所有$z</em>{t’},t’&lt;t$有一个自回归模型(e.g. GRU)$g<em>{ar}$推断得到当前时刻的$c_t$，利用对当前时刻的推测$c_t$，推断(用一个矩阵$W_k$进行映射)得到后面几个时刻的潜在表示序列的映射<strong>（预测值）</strong>$z’</em>{t+1}$、$z’<em>{t+2}$、$z’</em>{t+3}…$；将真实的$x<em>{t+1}$、$x</em>{t+2}$、$x<em>{t+3}…$通过$g</em>{enc}$得到的潜在表示序列<strong>（真实值）</strong>做损失函数，达到收敛。最后利用$c_t$完成下游任务。</p><h2 id="衡量-x-和-c-的相关性"><a href="#衡量-x-和-c-的相关性" class="headerlink" title="衡量$x$和$c$的相关性"></a>衡量$x$和$c$的相关性</h2><p>互信息可以很好的衡量相关性：</p><script type="math/tex; mode=display">I(x;c)=\sum\limits_{x,c}p(x,c)log\frac{p(x|c)}{p(x)}</script><p>但是由于不方便计算（可见MINE.md），作者采用一个正比于$\frac{p(x|c)}{p(x)}$的函数$f_k(x,c)$来代替，即：</p><script type="math/tex; mode=display">f_k(x_{t+k}, c_t)\propto \frac{p(x_{t+k}|c_t)}{p(x_{t+k})}</script><p>然后这个$f<em>k(x</em>{t+k}, c_t)$函数的具体计算表达式为:</p><script type="math/tex; mode=display">f_k(x_{t+k}, c_t)=exp(z^T_{t+k}W_kc_t)</script><p>我觉得应该才开看，第一步是$W<em>k^Tz</em>{t+k}$，用一个Linear层将$z<em>{t+k}$映射到与$c_t$同Size；第二步做$W_k^Tz</em>{t+k}$和$c<em>t$的内积，即$(W_k^Tz</em>{t+k})^T$$c<em>t$，展开为$z^T</em>{t+k}W_kc_t$；第三步做指数运算。</p><h2 id="衡量互信息"><a href="#衡量互信息" class="headerlink" title="衡量互信息"></a>衡量互信息</h2><p>经过一系列证明，可以得到：</p><script type="math/tex; mode=display">I(x_{t+k};c_t)\geq log(N)-\mathcal{L}_N</script><p>其中$\mathcal{L}_N$为：</p><script type="math/tex; mode=display">\mathcal{L}_N=-\mathop{\mathbb{E}}\limits_{X}[log\frac{f_k(x_{t+k}, c_t)}{\sum_{x_j\in X}f_k(x_j,c_t)}]</script><p>可见最小化$\mathcal{L}_N$即可完成最大化互信息量的下界。</p><p>其中，$p(x_{t+k},c_t)$ 指的是正在选用信号的片段$x_t$（正样本），而$p(x_j)$指的是我们可以随便从其他的声音信号里选择一个片段（负样本）。这就是<strong>对比</strong>的体现。</p><p>对$\mathcal{L}_N$反向梯度传播即可完成整个算法。</p><p>文章中还涉及了对图像、自然语言、语音的不同形式的信号的建模，有需要可以查看原文。</p>]]></content>
    
    
    <categories>
      
      <category>Paper Reading</category>
      
      <category>Self-Supervised Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>星座图</title>
    <link href="/2021/12/04/constellation/"/>
    <url>/2021/12/04/constellation/</url>
    
    <content type="html"><![CDATA[<h1 id="星座图"><a href="#星座图" class="headerlink" title="星座图"></a>星座图</h1><p>已知信号以IQ路表示：</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/92c9c4adef9ca809931193d74d875a22.png" alt="IMG_1101"></p><p>注意：</p><p>①相邻符号之间码元变化１bit（格雷码）</p><p>②相邻符号点之间的欧式距离越大，抗噪声能力越强</p><p>③随着SPS(每个符号的采样点个数)增加，星座图显得越“乱”。因为一个符号的相位和幅度信息增加了，在星座图上的点数也增多了，符号与符号之间的跳变变得平滑。如下图可见：</p><p>QPSK星座图符号位置：</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/b50efc495629ea035ec664c76517790b.png" alt="image-20210815164210448"></p><p>SPS=1，SNR=18dB，QPSK星座图:</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/f92376c8c9c8bdab82cc5ef29ff05741.png" alt="image-20210815164329496"></p><p>SPS=8，SNR=18dB，QPSK星座图:</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/41f4fa54c7dc87329d6f03b81473b78a.png" alt="image-20210815164424105"></p><p>SPS=32，SNR=18dB，QPSK星座图:</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/9001b3bf7d18301c23add6778f21da9c.png" alt="image-20210815164642830"><br>肉眼观察SPS=1最明显，调制识别正确率和SPS有没有关系呢？</p>]]></content>
    
    
    <categories>
      
      <category>basic knowledge</category>
      
    </categories>
    
    
    <tags>
      
      <tag>signal processing</tag>
      
      <tag>communication</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>卷积/滤波及Matlab实现</title>
    <link href="/2021/12/04/conv/"/>
    <url>/2021/12/04/conv/</url>
    
    <content type="html"><![CDATA[<h1 id="通信基础-卷积-滤波-原理及Matlab实现"><a href="#通信基础-卷积-滤波-原理及Matlab实现" class="headerlink" title="通信基础-卷积/滤波(原理及Matlab实现)"></a>通信基础-卷积/滤波(原理及Matlab实现)</h1><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>若有两个在定义域上可积的函数$f(x)$和$g(x)$，波形如下：</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/a9424a77d482f4dc01ddfa01d05be699.png" alt="55f37ca13c8e2d21fb00aa2bf65c6d1"></p><p>则卷积的定义为：</p><p>连续形式：<script type="math/tex">f(x)*g(x)=\int^{\infty}_{-\infty}g(\tau)f(x-\tau)</script></p><p>离散形式：<script type="math/tex">f(n)*g(n)=\sum_{i=-\infty}^{\infty}g(i)f(n-i)</script></p><p>看起来略微有点复杂，其物理意义就是将可积函数$f(x)$前后翻转颠倒（卷积中的-卷）；再进行相乘求积分/求和（卷积中的-积）。</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/08aba5b10d5b7cd6f3b3736b7a667b44.png" alt="f61355f876f0b6176d5b3f2767a0395"></p><p>对应的步骤拆解为上图，可以把$g(x)$看做一个窗，这个窗固定不动，$f(x)$在翻转后，从左到右进入窗，并与窗对应点相乘并求和/积分，当$f(x)$穿过整个窗后，卷积运算结束。</p><h2 id="Matlab仿真"><a href="#Matlab仿真" class="headerlink" title="Matlab仿真"></a>Matlab仿真</h2><p>有两种实现方式，第一种是调用其filter函数；第二种是手动运算。</p><h3 id="滤波器设计"><a href="#滤波器设计" class="headerlink" title="滤波器设计"></a>滤波器设计</h3><p>设计一个简单的低通滤波，分离开2KHz和4KHz。<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/486b7107a74144818d84642a5d8e0b31.png" alt="在这里插入图片描述"></p><h3 id="filter函数"><a href="#filter函数" class="headerlink" title="filter函数"></a>filter函数</h3><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token comment">% 测试卷积</span>clc<span class="token punctuation">;</span>clear<span class="token punctuation">;</span>close all<span class="token punctuation">;</span>Fs <span class="token operator">=</span> <span class="token number">20000</span><span class="token punctuation">;</span> <span class="token comment">%采样率</span>fc1 <span class="token operator">=</span> <span class="token number">2000</span><span class="token punctuation">;</span> <span class="token comment">%第一个正弦波频率2Khz</span>fc2 <span class="token operator">=</span> <span class="token number">4000</span><span class="token punctuation">;</span><span class="token comment">% 第二个正弦波频率4Khz</span>N <span class="token operator">=</span> <span class="token number">4096</span><span class="token punctuation">;</span><span class="token comment">%fft点数</span>t <span class="token operator">=</span> <span class="token number">0</span><span class="token operator">:</span><span class="token number">1</span><span class="token operator">/</span>Fs<span class="token operator">:</span><span class="token number">100</span><span class="token operator">/</span>Fs<span class="token punctuation">;</span><span class="token comment">%时间序列</span>y1 <span class="token operator">=</span> <span class="token function">cos</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span><span class="token keyword">pi</span><span class="token operator">*</span>fc1<span class="token operator">*</span>t<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">% 第一个正弦波</span>y2 <span class="token operator">=</span> <span class="token function">cos</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span><span class="token keyword">pi</span><span class="token operator">*</span>fc2<span class="token operator">*</span>t<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">% 第二个正弦波</span><span class="token function">figure</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token function">subplot</span><span class="token punctuation">(</span><span class="token number">211</span><span class="token punctuation">)</span><span class="token function">plot</span><span class="token punctuation">(</span>t<span class="token punctuation">,</span> y1<span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">)</span><span class="token function">xlabel</span><span class="token punctuation">(</span><span class="token string">'t'</span><span class="token punctuation">)</span><span class="token function">title</span><span class="token punctuation">(</span><span class="token string">'f=2KHz正弦波'</span><span class="token punctuation">)</span><span class="token function">subplot</span><span class="token punctuation">(</span><span class="token number">212</span><span class="token punctuation">)</span><span class="token function">plot</span><span class="token punctuation">(</span>t<span class="token punctuation">,</span> y2<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span><span class="token function">xlabel</span><span class="token punctuation">(</span><span class="token string">'t'</span><span class="token punctuation">)</span><span class="token function">title</span><span class="token punctuation">(</span><span class="token string">'f=4KHz正弦波'</span><span class="token punctuation">)</span><span class="token function">figure</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token function">subplot</span><span class="token punctuation">(</span><span class="token number">211</span><span class="token punctuation">)</span>y_mix <span class="token operator">=</span> y1<span class="token operator">+</span>y2<span class="token punctuation">;</span><span class="token comment">% 混合信号</span><span class="token function">plot</span><span class="token punctuation">(</span>t<span class="token punctuation">,</span> y_mix<span class="token punctuation">)</span><span class="token function">title</span><span class="token punctuation">(</span><span class="token string">'2KHz和4KHz信号混合后的波形'</span><span class="token punctuation">)</span><span class="token function">subplot</span><span class="token punctuation">(</span><span class="token number">212</span><span class="token punctuation">)</span>x <span class="token operator">=</span> <span class="token number">0</span><span class="token operator">:</span>Fs<span class="token operator">/</span>N<span class="token operator">:</span><span class="token punctuation">(</span>N<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">/</span>N<span class="token operator">*</span>Fs<span class="token punctuation">;</span> <span class="token comment">%频率序列</span><span class="token function">plot</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token function">abs</span><span class="token punctuation">(</span><span class="token function">fft</span><span class="token punctuation">(</span>y_mix<span class="token punctuation">,</span> N<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">% 做N点fft</span><span class="token function">xlabel</span><span class="token punctuation">(</span><span class="token string">'Hz'</span><span class="token punctuation">)</span><span class="token function">title</span><span class="token punctuation">(</span><span class="token string">'混合后的频谱图'</span><span class="token punctuation">)</span><span class="token comment">%使用自带filter函数滤波</span>filter_coffe <span class="token operator">=</span> <span class="token function">load</span><span class="token punctuation">(</span><span class="token string">'filter_coffe'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">% 读取滤波器系数，可直接使用filter designer设计低通滤波器</span>filter_coffe <span class="token operator">=</span> filter_coffe<span class="token punctuation">.</span>Num<span class="token punctuation">;</span>filter_after <span class="token operator">=</span> <span class="token function">filter</span><span class="token punctuation">(</span>filter_coffe<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> y_mix<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">% 使用filter函数滤波</span><span class="token function">figure</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token function">subplot</span><span class="token punctuation">(</span><span class="token number">211</span><span class="token punctuation">)</span><span class="token function">plot</span><span class="token punctuation">(</span>t<span class="token punctuation">,</span> filter_after<span class="token punctuation">)</span><span class="token function">title</span><span class="token punctuation">(</span><span class="token string">'使用filter函数滤波后时域图'</span><span class="token punctuation">)</span><span class="token function">xlabel</span><span class="token punctuation">(</span><span class="token string">'t'</span><span class="token punctuation">)</span><span class="token function">subplot</span><span class="token punctuation">(</span><span class="token number">212</span><span class="token punctuation">)</span><span class="token function">plot</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token function">abs</span><span class="token punctuation">(</span><span class="token function">fft</span><span class="token punctuation">(</span>filter_after<span class="token punctuation">,</span> N<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token function">title</span><span class="token punctuation">(</span><span class="token string">'使用filter函数滤波后频域图'</span><span class="token punctuation">)</span><span class="token function">xlabel</span><span class="token punctuation">(</span><span class="token string">'Hz'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="手动实现"><a href="#手动实现" class="headerlink" title="手动实现"></a>手动实现</h3><p>过程就和上面第一点中讲的完全相同，先翻转一个信号，再依点送入并和另外一个信号对应相乘求和/积分。</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token comment">% 自己定义滤波 先倒过来，然后一步一步往里推数据，再相乘求和。数据窗长应该和滤波器系数长度相同</span>fft_data <span class="token operator">=</span> <span class="token function">zeros</span><span class="token punctuation">(</span><span class="token function">length</span><span class="token punctuation">(</span>filter_coffe<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">%准备数据窗长</span>y_fft_in <span class="token operator">=</span> <span class="token function">zeros</span><span class="token punctuation">(</span><span class="token function">length</span><span class="token punctuation">(</span>filter_coffe<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token operator">+</span><span class="token function">length</span><span class="token punctuation">(</span>y_mix<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">% 先准备一个全0序列</span><span class="token function">y_fft_in</span><span class="token punctuation">(</span><span class="token function">length</span><span class="token punctuation">(</span>filter_coffe<span class="token punctuation">)</span><span class="token operator">:</span><span class="token keyword">end</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token function">y_mix</span><span class="token punctuation">(</span><span class="token keyword">end</span><span class="token operator">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">% 给全0序列后面填翻转后的数据。整个过程等于在给原始数据前面补0</span>y_fft_out <span class="token operator">=</span> <span class="token function">zeros</span><span class="token punctuation">(</span><span class="token function">length</span><span class="token punctuation">(</span>y_mix<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">% 准备输出数据的位置</span><span class="token keyword">for</span> step<span class="token operator">=</span><span class="token number">1</span><span class="token operator">:</span><span class="token number">1</span><span class="token operator">:</span><span class="token function">length</span><span class="token punctuation">(</span>y_mix<span class="token punctuation">)</span>       <span class="token function">y_fft_out</span><span class="token punctuation">(</span>step<span class="token punctuation">)</span> <span class="token operator">=</span> filter_coffe<span class="token operator">*</span><span class="token function">y_fft_in</span><span class="token punctuation">(</span>step<span class="token operator">:</span>step<span class="token operator">+</span><span class="token function">length</span><span class="token punctuation">(</span>filter_coffe<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">%相乘求和</span><span class="token keyword">end</span><span class="token function">figure</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token function">subplot</span><span class="token punctuation">(</span><span class="token number">211</span><span class="token punctuation">)</span><span class="token function">plot</span><span class="token punctuation">(</span>t<span class="token punctuation">,</span> y_fft_out<span class="token punctuation">)</span><span class="token function">title</span><span class="token punctuation">(</span><span class="token string">'手动实现滤波的时域图'</span><span class="token punctuation">)</span><span class="token function">xlabel</span><span class="token punctuation">(</span><span class="token string">'t'</span><span class="token punctuation">)</span><span class="token function">subplot</span><span class="token punctuation">(</span><span class="token number">212</span><span class="token punctuation">)</span><span class="token function">plot</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token function">abs</span><span class="token punctuation">(</span><span class="token function">fft</span><span class="token punctuation">(</span>y_fft_out<span class="token punctuation">,</span> N<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token function">title</span><span class="token punctuation">(</span><span class="token string">'手动实现滤波的频域图'</span><span class="token punctuation">)</span><span class="token function">xlabel</span><span class="token punctuation">(</span><span class="token string">'Hz'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>先产生两个频率的正弦波，并混合。<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/image-20210928215145850.png" width="60%"><br>混合后的时域和频域波形<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/image-20210928215156905.png" width="60%"><br>使用filter函数滤波结果<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/image-20210928215206566.png" width="60%"><br>使用自定义方法滤波:<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/image-20210928215215585.png" width="60%"></p>]]></content>
    
    
    <categories>
      
      <category>basic knowledge</category>
      
    </categories>
    
    
    <tags>
      
      <tag>signal processing</tag>
      
      <tag>communication</tag>
      
      <tag>matlab</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>word/latex插入矢量图</title>
    <link href="/2021/12/04/wordlatex2pdf/"/>
    <url>/2021/12/04/wordlatex2pdf/</url>
    
    <content type="html"><![CDATA[<h2 id="制作论文插图"><a href="#制作论文插图" class="headerlink" title="制作论文插图"></a>制作论文插图</h2><p>有人喜欢用visio，有人喜欢用drawio，我就不一样了，我喜欢的drawio+viso。这也没办法。drawio画图舒服，但是导出的矢量图插入word有bug，<a href="https://desk.draw.io/support/solutions/articles/16000042487">详情见这里</a>，但是我试了没有用，所以只能用drawio画好后，用visio打开，调整一下可能变化的格式，然后导出矢量图插入word。</p><h2 id="visio调整格式"><a href="#visio调整格式" class="headerlink" title="visio调整格式"></a>visio调整格式</h2><p>假如说现在已经在drawio画好了图，如下：<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/91f772eb97cb4b36a0deeb1110858011.png" alt="在这里插入图片描述"><br>保存为.svg文件<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/70a7bd2998054a5c98e28b7e9df889a1.png" alt="在这里插入图片描述"><br>然后用visio打开，如下：<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/0dfc294f0dd94f90812cf019edfae868.png" alt="在这里插入图片描述"><br>发现有个主要问题，就是用latex打的公式在visio中不能识别。我在visio和word套件中都是用的AxMath插件，类似于Mathtype。现在重新打公式。插入对象AxMath:<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/9e8e93b5ac3d4d139d06b9be8f5c3646.png" alt="在这里插入图片描述"><br>完成后结果如下：<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/de2bed6d89574ad781c8c8d9c1b79980.png" alt="在这里插入图片描述"><br>删掉周围的空白部分<br>①在空白处右键选择显示ShapeSheet<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/1e23f934a7ef417cb613b6f758775ad6.png" alt="在这里插入图片描述"><br>②将参数改为如下所示：<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/9a8699c59eb04682b43eac6763a1f086.png" alt="在这里插入图片描述"><br>③选择设计-&gt;大小-&gt;适应绘图<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/dcc9bd31b5374770bfeac8e08787f0b5.png" alt="在这里插入图片描述"><br>得到了一个没有白边的图：<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/9734dcf8d4cd447bb6f106171784b375.png" alt="在这里插入图片描述"></p><p>然后就是保存为矢量图，我习惯用.emf文件，不容易出问题。</p><h2 id="在word中插入"><a href="#在word中插入" class="headerlink" title="在word中插入"></a>在word中插入</h2><p>就如同插入图片，直接插入就可以</p><h2 id="转pdf"><a href="#转pdf" class="headerlink" title="转pdf"></a>转pdf</h2><p>转为pdf容易出现问题，<del>最好装上Adobe套件</del>：建议直接用系统自带的pdf打印机打印pdf，这样基本上不会出问题。<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/70b98db116e54f8c956fccbb28f21a3a.png" alt="在这里插入图片描述"><br>选择另存为Adobe PDF即可。</p><h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><p>如果选择的.svg，转为pdf后会出现公式模糊；不使用Adobe套件，矢量图的字体会放得极大，完全失真</p><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p>有时候用python画好的图，只需要保存为.svg格式：<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">plt<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span><span class="token string">'Acc with SNR.svg'</span><span class="token punctuation">,</span> <span class="token builtin">format</span><span class="token operator">=</span><span class="token string">'svg'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><br>直接插入word是不行的，线条会乱掉。解决办法是下一个<a href="https://inkscape.org/">inkscape</a>然后直接打开python导出的.svg矢量图。选中图像主体，按<code><strong>ctrl</strong>+<strong>shift</strong>+<strong>R</strong></code>,去除白边之后再另存为.emf文件即可。</p><h1 id="LaTex插入矢量图"><a href="#LaTex插入矢量图" class="headerlink" title="LaTex插入矢量图"></a>LaTex插入矢量图</h1><h2 id="制作矢量图"><a href="#制作矢量图" class="headerlink" title="制作矢量图"></a>制作矢量图</h2><p>visio画好图之后，另存为pdf。<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/c38ea1b813da42d8be1dd2b2bddc6077.png" alt="在这里插入图片描述"></p><h2 id="使用inkscape编辑"><a href="#使用inkscape编辑" class="headerlink" title="使用inkscape编辑"></a>使用inkscape编辑</h2><p>inkscape导入的pdf图有两个问题，第一是有黑色的边框；第二是有白边。我找到一种简单粗暴的解决方法：<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/dbdb92b8f7c54a54a8afbe9fdb9d5752.png" alt="在这里插入图片描述"></p><ol><li>先用inkscape打开pdf图<img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/b9baa2037d8247418842a55a8ab2bed9.png" alt="在这里插入图片描述"></li><li>选中要保存的主体并直接复制，<img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/b399e488cbcd43b5a6272ce53e445701.png" alt="在这里插入图片描述"></li><li>然后新建一个inkscape文档，直接粘贴，并在选中粘贴内容的情况下按<code><strong>ctrl</strong>+<strong>shift</strong>+<strong>R</strong></code>,去除白边之后再另存为.eps文件即可.<br><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/4847c3863aee42a99d839d376001ea2c.png" alt="在这里插入图片描述"></li></ol><h1 id="注意-1"><a href="#注意-1" class="headerlink" title="注意"></a>注意</h1><p>在word中推荐使用emf，在latex中推荐使用eps</p>]]></content>
    
    
    <categories>
      
      <category>utils</category>
      
      <category>latex</category>
      
    </categories>
    
    
    <tags>
      
      <tag>utils</tag>
      
      <tag>office</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python工具箱</title>
    <link href="/2021/12/04/pythonutils/"/>
    <url>/2021/12/04/pythonutils/</url>
    
    <content type="html"><![CDATA[<h1 id="记录常用的一些工具代码"><a href="#记录常用的一些工具代码" class="headerlink" title="记录常用的一些工具代码"></a>记录常用的一些工具代码</h1><h2 id="遍历某文件夹下的所有文件路径（递归）"><a href="#遍历某文件夹下的所有文件路径（递归）" class="headerlink" title="遍历某文件夹下的所有文件路径（递归）"></a>遍历某文件夹下的所有文件路径（递归）</h2><p>可以用来对某个数据集进行批量处理。这里只返回所有文件的路径， 并存储到一个list.txt文件中。<br><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_file_path</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> txt<span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    dir_path <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>path<span class="token punctuation">)</span>    <span class="token keyword">for</span> dp <span class="token keyword">in</span> dir_path<span class="token punctuation">:</span>        <span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isdir<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>path<span class="token punctuation">,</span> dp<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            get_file_path<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>path<span class="token punctuation">,</span> dp<span class="token punctuation">)</span><span class="token punctuation">,</span> txt<span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            txt<span class="token punctuation">.</span>append<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>path<span class="token punctuation">,</span> dp<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></p><h2 id="np-savez保存后的读取"><a href="#np-savez保存后的读取" class="headerlink" title="np.savez保存后的读取"></a>np.savez保存后的读取</h2><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">val_set_all <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'savemodel/fine_tune_test_set.npz'</span><span class="token punctuation">,</span> allow_pickle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> name <span class="token keyword">in</span> val_set_all<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    val_set_all<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> val_set_all<span class="token punctuation">[</span>name<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div><h2 id="JS散度"><a href="#JS散度" class="headerlink" title="JS散度"></a>JS散度</h2><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">loss_js</span><span class="token punctuation">(</span>p_output<span class="token punctuation">,</span> q_output<span class="token punctuation">,</span> get_softmax<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    KLDivLoss <span class="token operator">=</span> nn<span class="token punctuation">.</span>KLDivLoss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'batchmean'</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> get_softmax<span class="token punctuation">:</span>        p_output <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>p_output<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        q_output <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>q_output<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    mean_output <span class="token operator">=</span> <span class="token punctuation">(</span>p_output <span class="token operator">+</span> q_output<span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">2</span>    <span class="token keyword">return</span> <span class="token punctuation">(</span>KLDivLoss<span class="token punctuation">(</span>p_output<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> mean_output<span class="token punctuation">)</span> <span class="token operator">+</span> KLDivLoss<span class="token punctuation">(</span>q_output<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> mean_output<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">2</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h2 id="pytorch-设置随机种子"><a href="#pytorch-设置随机种子" class="headerlink" title="pytorch 设置随机种子"></a>pytorch 设置随机种子</h2><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">seed_torch</span><span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">1029</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>    os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'PYTHONHASHSEED'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">str</span><span class="token punctuation">(</span>seed<span class="token punctuation">)</span> <span class="token comment"># 为了禁止hash随机化，使得实验可复现</span>    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed_all<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>  <span class="token comment"># if you are using multi-GPU.</span>    torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">False</span>    torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h2 id="Pytorch梯度裁剪"><a href="#Pytorch梯度裁剪" class="headerlink" title="Pytorch梯度裁剪"></a>Pytorch梯度裁剪</h2><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>nn<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>clip_grad_norm_<span class="token punctuation">(</span>net1<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> max_norm<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> norm_type<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>nn<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>clip_grad_norm_<span class="token punctuation">(</span>net2<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> max_norm<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> norm_type<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div><h2 id="matplotlib写中文"><a href="#matplotlib写中文" class="headerlink" title="matplotlib写中文"></a>matplotlib写中文</h2><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'font.sans-serif'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'SimHei'</span><span class="token punctuation">]</span>plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'axes.unicode_minus'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">False</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><h2 id="多个list按其中一个排序，其余的跟着变"><a href="#多个list按其中一个排序，其余的跟着变" class="headerlink" title="多个list按其中一个排序，其余的跟着变"></a>多个list按其中一个排序，其余的跟着变</h2><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">u_idx <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>label <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token builtin">list</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token builtin">sorted</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>u_idx<span class="token punctuation">,</span> label<span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div>]]></content>
    
    
    <categories>
      
      <category>utils</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>utils</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hexo 工具箱</title>
    <link href="/2021/12/03/hexoutils/"/>
    <url>/2021/12/03/hexoutils/</url>
    
    <content type="html"><![CDATA[<h1 id="hexo本地文件同步到github"><a href="#hexo本地文件同步到github" class="headerlink" title="hexo本地文件同步到github"></a>hexo本地文件同步到github</h1><ol><li><p>github新建分支</p></li><li><p>将新分支设置为默认分支</p></li><li><p>将新分支clone到本地新文件夹A中</p></li><li><p>删除除了.git之外的所有文件。.git文件夹是隐藏文件夹</p></li><li><p>将本地文件除了.deploy_git和.git两个文件之外的所有文件全部复制，并粘贴到A</p></li><li><p>修改.gitignore文件中忽略的文件夹。因为我用的主题决定了我需要保留node_modules，所以将其中的/node_modules删除</p></li><li><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">git add .git commit -m &quot;add branch&quot;git push<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></li></ol><p>之后每次更新完博客，记得重复<code>步骤7</code></p><h1 id="在新电脑上clone博客文件"><a href="#在新电脑上clone博客文件" class="headerlink" title="在新电脑上clone博客文件"></a>在新电脑上clone博客文件</h1><p>安装git，安装nodejs，配置ssh key，安装hexo</p><ol><li><p>clone github 上的仓库</p></li><li><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">cd xxx.github.ionpm installnpm install hexo-deployer-git --save<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></li><li><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">hexo ghexo d<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></li></ol><p>每次打开博客文件夹，都需要同步一下。</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">git pull<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><h1 id="创建新文档"><a href="#创建新文档" class="headerlink" title="创建新文档"></a>创建新文档</h1><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">hexo new [layout] &lt;title&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>例如 hexo new mypage utils</p><p>意思是创建一个以mypage为模板的博客文件，名字叫做utils.md</p><p>注意 <code>mypage</code>是我自己定义的，自带的只有<code>post</code>,<code>draft</code>,<code>page</code>三种，默认是<code>post</code></p><h1 id="创建草稿不发布"><a href="#创建草稿不发布" class="headerlink" title="创建草稿不发布"></a>创建草稿不发布</h1><ol><li><p>创建草稿mydraft.md</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">hexo new draft mydraft<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></li><li><p>预览草稿</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">hexo server --draft<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></li><li><p>发布草稿mydraft.md</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">hexo publish draft mydraft<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></li></ol>]]></content>
    
    
    <categories>
      
      <category>utils</category>
      
    </categories>
    
    
    <tags>
      
      <tag>utils</tag>
      
      <tag>hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Self-Supervised Learning综述小结</title>
    <link href="/2021/12/03/Self-Supervised%20Learning/"/>
    <url>/2021/12/03/Self-Supervised%20Learning/</url>
    
    <content type="html"><![CDATA[<h2 id="Pre-train-Fine-tune"><a href="#Pre-train-Fine-tune" class="headerlink" title="Pre-train Fine-tune"></a>Pre-train Fine-tune</h2><p><strong>Pre-train Fine-tune</strong>算是一种Transfer Learning。</p><p>首先，假设按照SimCLR中的设定，将一般的模型分为两部分，分别为<strong>Encoder</strong>和<strong>Projection Head</strong>。<strong>Encoder</strong>结构类似于AutoEncoder中的Encoder部分，输出是一个低维的张量，可以称为输入数据的<strong>表征</strong>。<strong>Projection Head</strong>可以认为是一个全连接层，将Encoder输出的张量映射为更低维的张量（或者称为嵌入向量）。</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/pre_train&amp;finetune.svg" alt="pre_train&amp;finetune"></p><p><strong>Pre-train</strong>就是预训练<strong>Encoder</strong>部分，得到一个有用的<strong>表征</strong>，通过<strong>Projection Head</strong>得到输出的嵌入向量，进行损失函数计算和模型更新。然后在不同的<strong>下游任务</strong>中，删掉<strong>Projection Head</strong>，<strong>重新训练</strong>。</p><p>预训练<strong>Encoder</strong>的过程就是<strong>Pre-train</strong>；删掉<strong>Projection Head</strong>，<strong>重新训练</strong>的过程就叫做<strong>Fine-tune</strong></p><p>此处的<strong>重新训练</strong>可以分为两种：</p><ol><li>ConvNet as fixed feature extractor：即删掉<strong>Projection Head</strong>后，重新训练一个<strong>Projection Head</strong>。</li><li>Fine-tuning the ConvNet：即对<strong>Encoder</strong>进行微调，同时重新训练一个<strong>Projection Head</strong></li></ol><p>对于<strong>Self-supervised Learning</strong>，要明确其严格意义上讲叫做<strong>无监督表示学习</strong>。和传统的无监督学习不同，<strong>SSL</strong>最终还是会用到有标记数据，只不过相对于监督训练，可以在极小的有标记数据下实现较高的正确率。</p><p><strong>SSL</strong>一般将<strong>Pre-train</strong>和下游任务的<strong>fine-tune</strong>分开，不过也有很多文章尝试将二者结合起来。总而言之，四个词总结为：</p><blockquote><p>Unsupervised Pre-train, Supervised Fine-tune.</p></blockquote><h2 id="Self-supervised-Learning"><a href="#Self-supervised-Learning" class="headerlink" title="Self-supervised Learning"></a>Self-supervised Learning</h2><p><strong>Self-supervised Learning</strong>就是通过大量无标记数据，找寻数据之间的内在关系，建立一个能够提取泛化特征的<strong>Encoder</strong>，然后根据下游任务的需要，在下游任务的少量有标记数据集中进行<strong>Fine-tune</strong>。从生物的角度讲，可以理解为在无标记数据集中培育一个干细胞，然后在具体的下游任务中，利用少量资源，就可以将干细胞分化为红细胞、白细胞、上皮细胞；而不是每次都搞大量资源从头开始造不同结构的不同细胞。根据寻找这种内在关系的方式不同，可以将<strong>SSL</strong>分为两个大类（也有文章分为三个大类）：</p><ol><li>基于生成/预测的SSL</li><li>基于对比的SSL</li></ol><h3 id="基于生成-预测的SSL"><a href="#基于生成-预测的SSL" class="headerlink" title="基于生成/预测的SSL"></a>基于生成/预测的SSL</h3><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/image-20210828153720420.png" alt="基于生成/预测的SSL"></p><p>对于第一种，基于生成/预测的SSL，典型的有<a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/Pathak_Context_Encoders_Feature_CVPR_2016_paper.pdf">Context Encoders: Feature Learning by Inpainting</a>，通过对图像的一部分扣除，将扣除后剩余部分进行Encoder，输出一个大小与扣除部分相同的张量，然后将扣除的部分和Encoder输出的部分做Loss，就可以让Encoder全面的知道输入的图片究竟是怎么样的。（当然也可以用来做一些图像补全工作）</p><p><img src="https://mymarkdown-pic.oss-cn-chengdu.aliyuncs.com/img441/image-20210828195036104.png" alt="SSL用于图像补全"></p><h3 id="基于对比的SSL"><a href="#基于对比的SSL" class="headerlink" title="基于对比的SSL"></a>基于对比的SSL</h3><p>这部分是目前研究的重点，有一些典型的文章：</p><h4 id="DIM"><a href="#DIM" class="headerlink" title="DIM"></a>DIM</h4><p><a href="https://arxiv.org/pdf/1808.06670.pdf?source=post_page---------------------------">Learning Deep Representations By Mutual Information Estimation And Maximization</a></p><h4 id="CPC"><a href="#CPC" class="headerlink" title="CPC"></a>CPC</h4><p><a href="https://arxiv.org/pdf/1807.03748.pdf">Representation Learning with Contrastive Predictive Coding</a></p><h4 id="CMC"><a href="#CMC" class="headerlink" title="CMC"></a>CMC</h4><p><a href="https://arxiv.org/pdf/1906.05849.pdf">Contrastive Multiview Coding</a></p><h4 id="MoCo"><a href="#MoCo" class="headerlink" title="MoCo"></a>MoCo</h4><p><a href="https://arxiv.org/pdf/1911.05722.pdf">Momentum Contrast for Unsupervised Visual Representation Learning</a></p><h4 id="SimCLR"><a href="#SimCLR" class="headerlink" title="SimCLR(*)"></a>SimCLR(<strong>*</strong>)</h4><p>SimCLR及其改进版本SimCLR-v2，其完整过程请参考（大佬们已经总结得十分详细了，没有必要再整理了）：</p><p><a href="https://zhuanlan.zhihu.com/p/378953015">详细介绍</a></p><p>[精简思路](</p>]]></content>
    
    
    <categories>
      
      <category>Paper Reading</category>
      
      <category>Self-Supervised Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Deep Learning</tag>
      
      <tag>overview</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
